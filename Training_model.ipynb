{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'crossRefQuery'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/sedv8808/HT-Data/UWisc/article-relevance/Training_model.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sedv8808/HT-Data/UWisc/article-relevance/Training_model.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sedv8808/HT-Data/UWisc/article-relevance/Training_model.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marticle_relevance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mar\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sedv8808/HT-Data/UWisc/article-relevance/Training_model.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/src/article_relevance/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpredToPQ\u001b[39;00m \u001b[39mimport\u001b[39;00m predToPQ\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mNeotomaOneHotEncoder\u001b[39;00m \u001b[39mimport\u001b[39;00m NeotomaOneHotEncoder\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mupdateSource\u001b[39;00m \u001b[39mimport\u001b[39;00m updateSource\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/src/article_relevance/updateSource.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcrossRefQuery\u001b[39;00m \u001b[39mimport\u001b[39;00m crossRefQuery\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpq\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'crossRefQuery'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import src.article_relevance as ar\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2670"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publicationDF = pd.read_parquet('data/parquet/publicationMetadataDF.parquet', engine='fastparquet')\n",
    "annotationDF = pd.read_parquet('data/parquet/AnnotationDF.parquet')\n",
    "publicationDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotationDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotation\n",
       "Not Neotoma      1775\n",
       "Neotoma           852\n",
       "Maybe Neotoma      73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotationDF['annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI\n",
       "10.1177/095968369400400404          1\n",
       "10.1073/pnas.1222239110             1\n",
       "10.1016/j.foreco.2010.05.001        1\n",
       "10.1016/j.revpalbo.2011.05.003      1\n",
       "10.1111/j.1365-2699.2011.02618.x    1\n",
       "                                   ..\n",
       "10.5194/bg-2016-354                 1\n",
       "10.1080/02724634.2015.1113803       1\n",
       "10.1016/s0367-2530(17)30981-7       1\n",
       "10.1016/j.quaint.2005.03.004        1\n",
       "10.1540/jsmr.59.28                  1\n",
       "Name: count, Length: 2670, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publicationDF['DOI'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Parquet\n",
    "\n",
    "The Prediction PQ file will contain the following columns:\n",
    "```python\n",
    "['DOI', 'prediction', 'predict_proba', 'model_metadata', 'prediction_date']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Embeddings to the publicationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 09:48:16.366822\n",
      "2023-10-10 09:48:16,367 - addEmbeddings.py:20 - addEmbeddings - INFO - Starting Sentence Embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 10810.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 09:48:31,835 - addEmbeddings.py:34 - addEmbeddings - INFO - Tokenizing sentences and creating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 11:11:36,571 - addEmbeddings.py:61 - addEmbeddings - INFO - Sentence embedding completed.\n",
      "2023-10-10 11:11:37.404899\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "embeddingsDF = ar.addEmbeddings(publicationDF, 'titleSubtitleAbstract')\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CrossRefQueryDate', 'DOI', 'URL', 'abstract', 'author',\n",
       "       'container-title', 'language', 'published', 'publisher', 'subject',\n",
       "       ...\n",
       "       'embedding_758', 'embedding_759', 'embedding_760', 'embedding_761',\n",
       "       'embedding_762', 'embedding_763', 'embedding_764', 'embedding_765',\n",
       "       'embedding_766', 'embedding_767'],\n",
       "      dtype='object', length=782)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols = [col for col in embeddingsDF.columns if col.startswith(\"embedding_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols.append(\"DOI\")\n",
    "selectedCols.sort(key=lambda col: col != \"DOI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsDF = embeddingsDF.loc[:, selectedCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_758</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.quascirev.2014.04.014</td>\n",
       "      <td>1.460713</td>\n",
       "      <td>1.039954</td>\n",
       "      <td>-0.695859</td>\n",
       "      <td>1.206938</td>\n",
       "      <td>-1.106794</td>\n",
       "      <td>-0.166607</td>\n",
       "      <td>0.261164</td>\n",
       "      <td>-0.251705</td>\n",
       "      <td>0.275001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750866</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>-1.333266</td>\n",
       "      <td>-1.030996</td>\n",
       "      <td>-0.712262</td>\n",
       "      <td>-0.215967</td>\n",
       "      <td>-0.134665</td>\n",
       "      <td>-0.285963</td>\n",
       "      <td>0.342186</td>\n",
       "      <td>-0.005781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1002/gea.10020</td>\n",
       "      <td>0.770710</td>\n",
       "      <td>1.049734</td>\n",
       "      <td>-0.231182</td>\n",
       "      <td>0.321153</td>\n",
       "      <td>-1.076258</td>\n",
       "      <td>0.213778</td>\n",
       "      <td>-0.017972</td>\n",
       "      <td>-0.489939</td>\n",
       "      <td>0.222379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080440</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.561089</td>\n",
       "      <td>-0.206273</td>\n",
       "      <td>-0.695066</td>\n",
       "      <td>-0.604755</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.094507</td>\n",
       "      <td>-0.153755</td>\n",
       "      <td>-0.240465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1139/e80-122</td>\n",
       "      <td>0.532121</td>\n",
       "      <td>0.436422</td>\n",
       "      <td>-0.784752</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>-0.036988</td>\n",
       "      <td>1.149151</td>\n",
       "      <td>-0.223610</td>\n",
       "      <td>-0.165904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175802</td>\n",
       "      <td>-0.785979</td>\n",
       "      <td>-0.373426</td>\n",
       "      <td>-0.472257</td>\n",
       "      <td>-0.790648</td>\n",
       "      <td>-1.567279</td>\n",
       "      <td>-0.251331</td>\n",
       "      <td>-0.473002</td>\n",
       "      <td>-0.605666</td>\n",
       "      <td>0.727403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               DOI  embedding_0  embedding_1  embedding_2  \\\n",
       "0  10.1016/j.quascirev.2014.04.014     1.460713     1.039954    -0.695859   \n",
       "1                10.1002/gea.10020     0.770710     1.049734    -0.231182   \n",
       "2                  10.1139/e80-122     0.532121     0.436422    -0.784752   \n",
       "\n",
       "   embedding_3  embedding_4  embedding_5  embedding_6  embedding_7  \\\n",
       "0     1.206938    -1.106794    -0.166607     0.261164    -0.251705   \n",
       "1     0.321153    -1.076258     0.213778    -0.017972    -0.489939   \n",
       "2     0.379681    -0.057600    -0.036988     1.149151    -0.223610   \n",
       "\n",
       "   embedding_8  ...  embedding_758  embedding_759  embedding_760  \\\n",
       "0     0.275001  ...       0.750866       0.160514      -1.333266   \n",
       "1     0.222379  ...      -0.080440      -0.000156      -0.561089   \n",
       "2    -0.165904  ...      -0.175802      -0.785979      -0.373426   \n",
       "\n",
       "   embedding_761  embedding_762  embedding_763  embedding_764  embedding_765  \\\n",
       "0      -1.030996      -0.712262      -0.215967      -0.134665      -0.285963   \n",
       "1      -0.206273      -0.695066      -0.604755       0.050028      -0.094507   \n",
       "2      -0.472257      -0.790648      -1.567279      -0.251331      -0.473002   \n",
       "\n",
       "   embedding_766  embedding_767  \n",
       "0       0.342186      -0.005781  \n",
       "1      -0.153755      -0.240465  \n",
       "2      -0.605666       0.727403  \n",
       "\n",
       "[3 rows x 769 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingsDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI\n",
       "10.1177/095968369400400404          1\n",
       "10.1073/pnas.1222239110             1\n",
       "10.1016/j.foreco.2010.05.001        1\n",
       "10.1016/j.revpalbo.2011.05.003      1\n",
       "10.1111/j.1365-2699.2011.02618.x    1\n",
       "                                   ..\n",
       "10.5194/bg-2016-354                 1\n",
       "10.1080/02724634.2015.1113803       1\n",
       "10.1016/s0367-2530(17)30981-7       1\n",
       "10.1016/j.quaint.2005.03.004        1\n",
       "10.29262/ram.v68i4.842              1\n",
       "Name: count, Length: 2670, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingsDF['DOI'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2670"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publicationDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingsDF.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddingsDF.to_parquet('data/parquet/embeddingsDF.parquet', engine='fastparquet', compression='snappy', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run From Here\n",
    "## (if embeddings file is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import src.article_relevance as ar\n",
    "\n",
    "publicationDF = pd.read_parquet('data/parquet/publicationMetadataDF.parquet', engine='fastparquet')\n",
    "annotationDF = pd.read_parquet('data/parquet/AnnotationDF.parquet')\n",
    "embeddingsDF = pd.read_parquet('data/parquet/embeddingsDF.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossRefQueryDate</th>\n",
       "      <th>DOI</th>\n",
       "      <th>URL</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>container-title</th>\n",
       "      <th>language</th>\n",
       "      <th>published</th>\n",
       "      <th>publisher</th>\n",
       "      <th>subject</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_758</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-06 22:41:36.395841</td>\n",
       "      <td>10.1016/j.quascirev.2014.04.014</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.quascirev.2014.04.014</td>\n",
       "      <td></td>\n",
       "      <td>[{'ORCID': 'http://orcid.org/0000-0001-5732-37...</td>\n",
       "      <td>Quaternary Science Reviews</td>\n",
       "      <td>en</td>\n",
       "      <td>{'date-parts': [[2014, 6]]}</td>\n",
       "      <td>Elsevier BV</td>\n",
       "      <td>[Geology, Archeology, Archeology, Ecology, Evo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750866</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>-1.333266</td>\n",
       "      <td>-1.030996</td>\n",
       "      <td>-0.712262</td>\n",
       "      <td>-0.215967</td>\n",
       "      <td>-0.134665</td>\n",
       "      <td>-0.285963</td>\n",
       "      <td>0.342186</td>\n",
       "      <td>-0.005781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CrossRefQueryDate                              DOI  \\\n",
       "0 2023-10-06 22:41:36.395841  10.1016/j.quascirev.2014.04.014   \n",
       "\n",
       "                                                 URL abstract  \\\n",
       "0  http://dx.doi.org/10.1016/j.quascirev.2014.04.014            \n",
       "\n",
       "                                              author  \\\n",
       "0  [{'ORCID': 'http://orcid.org/0000-0001-5732-37...   \n",
       "\n",
       "              container-title language                    published  \\\n",
       "0  Quaternary Science Reviews       en  {'date-parts': [[2014, 6]]}   \n",
       "\n",
       "     publisher                                            subject  ...  \\\n",
       "0  Elsevier BV  [Geology, Archeology, Archeology, Ecology, Evo...  ...   \n",
       "\n",
       "  embedding_758 embedding_759 embedding_760  embedding_761  embedding_762  \\\n",
       "0      0.750866      0.160514     -1.333266      -1.030996      -0.712262   \n",
       "\n",
       "   embedding_763  embedding_764  embedding_765  embedding_766  embedding_767  \n",
       "0      -0.215967      -0.134665      -0.285963       0.342186      -0.005781  \n",
       "\n",
       "[1 rows x 782 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddingsDF = publicationDF.merge(embeddingsDF, on = \"DOI\")\n",
    "embeddingsDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CrossRefQueryDate</th>\n",
       "      <th>DOI</th>\n",
       "      <th>URL</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>container-title</th>\n",
       "      <th>language</th>\n",
       "      <th>published</th>\n",
       "      <th>publisher</th>\n",
       "      <th>subject</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "      <th>annotation</th>\n",
       "      <th>annotator</th>\n",
       "      <th>annotationDate</th>\n",
       "      <th>verified</th>\n",
       "      <th>verifiedBy</th>\n",
       "      <th>verifiedTimeStamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-06 22:41:36.395841</td>\n",
       "      <td>10.1016/j.quascirev.2014.04.014</td>\n",
       "      <td>http://dx.doi.org/10.1016/j.quascirev.2014.04.014</td>\n",
       "      <td></td>\n",
       "      <td>[{'ORCID': 'http://orcid.org/0000-0001-5732-37...</td>\n",
       "      <td>Quaternary Science Reviews</td>\n",
       "      <td>en</td>\n",
       "      <td>{'date-parts': [[2014, 6]]}</td>\n",
       "      <td>Elsevier BV</td>\n",
       "      <td>[Geology, Archeology, Archeology, Ecology, Evo...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134665</td>\n",
       "      <td>-0.285963</td>\n",
       "      <td>0.342186</td>\n",
       "      <td>-0.005781</td>\n",
       "      <td>Neotoma</td>\n",
       "      <td>Simon J. Goring</td>\n",
       "      <td>2023-10-06 23:05:47</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 788 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CrossRefQueryDate                              DOI  \\\n",
       "0 2023-10-06 22:41:36.395841  10.1016/j.quascirev.2014.04.014   \n",
       "\n",
       "                                                 URL abstract  \\\n",
       "0  http://dx.doi.org/10.1016/j.quascirev.2014.04.014            \n",
       "\n",
       "                                              author  \\\n",
       "0  [{'ORCID': 'http://orcid.org/0000-0001-5732-37...   \n",
       "\n",
       "              container-title language                    published  \\\n",
       "0  Quaternary Science Reviews       en  {'date-parts': [[2014, 6]]}   \n",
       "\n",
       "     publisher                                            subject  ...  \\\n",
       "0  Elsevier BV  [Geology, Archeology, Archeology, Ecology, Evo...  ...   \n",
       "\n",
       "  embedding_764 embedding_765 embedding_766  embedding_767  annotation  \\\n",
       "0     -0.134665     -0.285963      0.342186      -0.005781     Neotoma   \n",
       "\n",
       "         annotator       annotationDate  verified  verifiedBy  \\\n",
       "0  Simon J. Goring  2023-10-06 23:05:47        No        None   \n",
       "\n",
       "   verifiedTimeStamp  \n",
       "0               None  \n",
       "\n",
       "[1 rows x 788 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeDF = embeddingsDF.merge(annotationDF, on = 'DOI')\n",
    "completeDF.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeDF.loc[(completeDF['annotation']!= 'Neotoma'), 'target'] = 0\n",
    "completeDF.loc[(completeDF['annotation']== 'Neotoma'), 'target'] = 1\n",
    "completeDF.loc[(completeDF['annotation']== 'Maybe Neotoma'), 'target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0.0    1754\n",
       "1.0     875\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeDF['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI\n",
       "10.1540/jsmr.59.28                              1\n",
       "10.1016/j.quascirev.2014.04.014                 1\n",
       "10.1002/gea.10020                               1\n",
       "10.1139/e80-122                                 1\n",
       "10.1016/j.quaint.2015.05.009                    1\n",
       "                                               ..\n",
       "10.1139/e04-081                                 1\n",
       "10.1130/0091-7613(2000)28<51:rroatv>2.0.co;2    1\n",
       "10.1080/00173134.2014.927916                    1\n",
       "10.1016/j.yqres.2006.11.004                     1\n",
       "10.1016/j.yqres.2007.12.002                     1\n",
       "Name: count, Length: 2629, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeDF['DOI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols = [col for col in completeDF.columns if col.startswith('embedding_')]\n",
    "selectedCols = selectedCols + ['subject', 'container-title', 'DOI']\n",
    "selectedCols.sort(key=lambda col: (col != 'subject') & (col != 'container-title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CrossRefQueryDate', 'DOI', 'URL', 'abstract', 'author',\n",
       "       'container-title', 'language', 'published', 'publisher', 'subject',\n",
       "       ...\n",
       "       'embedding_765', 'embedding_766', 'embedding_767', 'annotation',\n",
       "       'annotator', 'annotationDate', 'verified', 'verifiedBy',\n",
       "       'verifiedTimeStamp', 'target'],\n",
       "      dtype='object', length=789)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = completeDF[selectedCols]\n",
    "y = completeDF['target']\n",
    "# author might lead to bias \n",
    "# we are only considering english text, so drop language\n",
    "# title subtitle and abstract have already been used with the embeddings\n",
    "# does it matter when it was published\n",
    "# must be used subject, container-title(journal), 'publisher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2629"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>container-title</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_759</th>\n",
       "      <th>embedding_760</th>\n",
       "      <th>embedding_761</th>\n",
       "      <th>embedding_762</th>\n",
       "      <th>embedding_763</th>\n",
       "      <th>embedding_764</th>\n",
       "      <th>embedding_765</th>\n",
       "      <th>embedding_766</th>\n",
       "      <th>embedding_767</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Geology, Archeology, Archeology, Ecology, Evo...</td>\n",
       "      <td>Quaternary Science Reviews</td>\n",
       "      <td>1.460713</td>\n",
       "      <td>1.039954</td>\n",
       "      <td>-0.695859</td>\n",
       "      <td>1.206938</td>\n",
       "      <td>-1.106794</td>\n",
       "      <td>-0.166607</td>\n",
       "      <td>0.261164</td>\n",
       "      <td>-0.251705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>-1.333266</td>\n",
       "      <td>-1.030996</td>\n",
       "      <td>-0.712262</td>\n",
       "      <td>-0.215967</td>\n",
       "      <td>-0.134665</td>\n",
       "      <td>-0.285963</td>\n",
       "      <td>0.342186</td>\n",
       "      <td>-0.005781</td>\n",
       "      <td>10.1016/j.quascirev.2014.04.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Earth and Planetary Sciences (miscellaneous),...</td>\n",
       "      <td>Geoarchaeology</td>\n",
       "      <td>0.770710</td>\n",
       "      <td>1.049734</td>\n",
       "      <td>-0.231182</td>\n",
       "      <td>0.321153</td>\n",
       "      <td>-1.076258</td>\n",
       "      <td>0.213778</td>\n",
       "      <td>-0.017972</td>\n",
       "      <td>-0.489939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.561089</td>\n",
       "      <td>-0.206273</td>\n",
       "      <td>-0.695066</td>\n",
       "      <td>-0.604755</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.094507</td>\n",
       "      <td>-0.153755</td>\n",
       "      <td>-0.240465</td>\n",
       "      <td>10.1002/gea.10020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[General Earth and Planetary Sciences]</td>\n",
       "      <td>Canadian Journal of Earth Sciences</td>\n",
       "      <td>0.532121</td>\n",
       "      <td>0.436422</td>\n",
       "      <td>-0.784752</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>-0.036988</td>\n",
       "      <td>1.149151</td>\n",
       "      <td>-0.223610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785979</td>\n",
       "      <td>-0.373426</td>\n",
       "      <td>-0.472257</td>\n",
       "      <td>-0.790648</td>\n",
       "      <td>-1.567279</td>\n",
       "      <td>-0.251331</td>\n",
       "      <td>-0.473002</td>\n",
       "      <td>-0.605666</td>\n",
       "      <td>0.727403</td>\n",
       "      <td>10.1139/e80-122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Earth-Surface Processes]</td>\n",
       "      <td>Quaternary International</td>\n",
       "      <td>0.932359</td>\n",
       "      <td>0.706798</td>\n",
       "      <td>-0.256035</td>\n",
       "      <td>1.202882</td>\n",
       "      <td>-1.088827</td>\n",
       "      <td>-0.545841</td>\n",
       "      <td>0.211784</td>\n",
       "      <td>-0.381181</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.129424</td>\n",
       "      <td>-1.327057</td>\n",
       "      <td>-1.357510</td>\n",
       "      <td>-0.634971</td>\n",
       "      <td>0.032592</td>\n",
       "      <td>-0.148837</td>\n",
       "      <td>-0.332732</td>\n",
       "      <td>0.083071</td>\n",
       "      <td>-0.068068</td>\n",
       "      <td>10.1016/j.quaint.2015.05.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Paleontology, Earth-Surface Processes, Ecolog...</td>\n",
       "      <td>The Holocene</td>\n",
       "      <td>0.039765</td>\n",
       "      <td>0.350768</td>\n",
       "      <td>-0.579025</td>\n",
       "      <td>0.674440</td>\n",
       "      <td>-0.874110</td>\n",
       "      <td>-0.556694</td>\n",
       "      <td>1.152852</td>\n",
       "      <td>0.131883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092944</td>\n",
       "      <td>-1.255777</td>\n",
       "      <td>-0.766077</td>\n",
       "      <td>-0.348673</td>\n",
       "      <td>-0.659905</td>\n",
       "      <td>-0.282952</td>\n",
       "      <td>-0.243913</td>\n",
       "      <td>-0.809546</td>\n",
       "      <td>0.621064</td>\n",
       "      <td>10.1191/0959683604hl761rp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject  \\\n",
       "0  [Geology, Archeology, Archeology, Ecology, Evo...   \n",
       "1  [Earth and Planetary Sciences (miscellaneous),...   \n",
       "2             [General Earth and Planetary Sciences]   \n",
       "3                          [Earth-Surface Processes]   \n",
       "4  [Paleontology, Earth-Surface Processes, Ecolog...   \n",
       "\n",
       "                      container-title  embedding_0  embedding_1  embedding_2  \\\n",
       "0          Quaternary Science Reviews     1.460713     1.039954    -0.695859   \n",
       "1                      Geoarchaeology     0.770710     1.049734    -0.231182   \n",
       "2  Canadian Journal of Earth Sciences     0.532121     0.436422    -0.784752   \n",
       "3            Quaternary International     0.932359     0.706798    -0.256035   \n",
       "4                        The Holocene     0.039765     0.350768    -0.579025   \n",
       "\n",
       "   embedding_3  embedding_4  embedding_5  embedding_6  embedding_7  ...  \\\n",
       "0     1.206938    -1.106794    -0.166607     0.261164    -0.251705  ...   \n",
       "1     0.321153    -1.076258     0.213778    -0.017972    -0.489939  ...   \n",
       "2     0.379681    -0.057600    -0.036988     1.149151    -0.223610  ...   \n",
       "3     1.202882    -1.088827    -0.545841     0.211784    -0.381181  ...   \n",
       "4     0.674440    -0.874110    -0.556694     1.152852     0.131883  ...   \n",
       "\n",
       "   embedding_759  embedding_760  embedding_761  embedding_762  embedding_763  \\\n",
       "0       0.160514      -1.333266      -1.030996      -0.712262      -0.215967   \n",
       "1      -0.000156      -0.561089      -0.206273      -0.695066      -0.604755   \n",
       "2      -0.785979      -0.373426      -0.472257      -0.790648      -1.567279   \n",
       "3      -0.129424      -1.327057      -1.357510      -0.634971       0.032592   \n",
       "4       0.092944      -1.255777      -0.766077      -0.348673      -0.659905   \n",
       "\n",
       "   embedding_764  embedding_765  embedding_766  embedding_767  \\\n",
       "0      -0.134665      -0.285963       0.342186      -0.005781   \n",
       "1       0.050028      -0.094507      -0.153755      -0.240465   \n",
       "2      -0.251331      -0.473002      -0.605666       0.727403   \n",
       "3      -0.148837      -0.332732       0.083071      -0.068068   \n",
       "4      -0.282952      -0.243913      -0.809546       0.621064   \n",
       "\n",
       "                               DOI  \n",
       "0  10.1016/j.quascirev.2014.04.014  \n",
       "1                10.1002/gea.10020  \n",
       "2                  10.1139/e80-122  \n",
       "3     10.1016/j.quaint.2015.05.009  \n",
       "4        10.1191/0959683604hl761rp  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2629"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` markdown\n",
    "Neotoma Encoder\n",
    "['subject']\n",
    "\n",
    "Count Vectorizer (BOW)\n",
    "['container-title']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up features\n",
      "Beginning training\n",
      "Training logisticregression.\n",
      "Starting fit at 2023-10-12_11-07-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decisiontreeclassifier.\n",
      "Starting fit at 2023-10-12_11-07-42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training kneighborsclassifier.\n",
      "Starting fit at 2023-10-12_11-08-44\n",
      "Training bernoullinb.\n",
      "Starting fit at 2023-10-12_11-09-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training randomforestclassifier.\n",
      "Starting fit at 2023-10-12_11-09-29\n",
      "finished process; returning results\n"
     ]
    }
   ],
   "source": [
    "resultsDict = ar.relevancePredictTrain(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0 days 00:00:35.780862</td>\n",
       "      <td>0.882713</td>\n",
       "      <td>0.929025</td>\n",
       "      <td>0.980495</td>\n",
       "      <td>0.955302</td>\n",
       "      <td>0.740298</td>\n",
       "      <td>0.778817</td>\n",
       "      <td>0.821906</td>\n",
       "      <td>0.860675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0 days 00:01:02.622119</td>\n",
       "      <td>0.921820</td>\n",
       "      <td>0.916272</td>\n",
       "      <td>0.911540</td>\n",
       "      <td>0.944245</td>\n",
       "      <td>0.628489</td>\n",
       "      <td>0.618093</td>\n",
       "      <td>0.611559</td>\n",
       "      <td>0.743718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0 days 00:00:33.838205</td>\n",
       "      <td>0.745343</td>\n",
       "      <td>0.740661</td>\n",
       "      <td>0.736137</td>\n",
       "      <td>0.827033</td>\n",
       "      <td>0.700154</td>\n",
       "      <td>0.687811</td>\n",
       "      <td>0.676240</td>\n",
       "      <td>0.789345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0 days 00:00:11.096299</td>\n",
       "      <td>0.729207</td>\n",
       "      <td>0.579243</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.648956</td>\n",
       "      <td>0.710082</td>\n",
       "      <td>0.568863</td>\n",
       "      <td>0.474844</td>\n",
       "      <td>0.643826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0 days 00:01:15.430216</td>\n",
       "      <td>0.989957</td>\n",
       "      <td>0.994953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996671</td>\n",
       "      <td>0.613998</td>\n",
       "      <td>0.709492</td>\n",
       "      <td>0.842258</td>\n",
       "      <td>0.833569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               classifier               Fit Time  train_recall  train_f1  \\\n",
       "0      LogisticRegression 0 days 00:00:35.780862      0.882713  0.929025   \n",
       "1  DecisionTreeClassifier 0 days 00:01:02.622119      0.921820  0.916272   \n",
       "2    KNeighborsClassifier 0 days 00:00:33.838205      0.745343  0.740661   \n",
       "3             BernoulliNB 0 days 00:00:11.096299      0.729207  0.579243   \n",
       "4  RandomForestClassifier 0 days 00:01:15.430216      0.989957  0.994953   \n",
       "\n",
       "   train_precision  train_accuracy  test_recall   test_f1  test_precision  \\\n",
       "0         0.980495        0.955302     0.740298  0.778817        0.821906   \n",
       "1         0.911540        0.944245     0.628489  0.618093        0.611559   \n",
       "2         0.736137        0.827033     0.700154  0.687811        0.676240   \n",
       "3         0.480476        0.648956     0.710082  0.568863        0.474844   \n",
       "4         1.000000        0.996671     0.613998  0.709492        0.842258   \n",
       "\n",
       "   test_accuracy  \n",
       "0       0.860675  \n",
       "1       0.743718  \n",
       "2       0.789345  \n",
       "3       0.643826  \n",
       "4       0.833569  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(resultsDict['report'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "DecisionTreeClassifier\n",
      "KNeighborsClassifier\n",
      "BernoulliNB\n",
      "RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "testResults = list()\n",
    "\n",
    "for counter, model in enumerate(resultsDict['model']):\n",
    "    individualResults = dict()\n",
    "    individualResults['DOI'] = X_test['DOI']\n",
    "    individualResults['model_name'] = resultsDict['model_name'][counter]\n",
    "    print(resultsDict['model_name'][counter])\n",
    "    individualResults['prediction'] = model.predict(X_test)\n",
    "    individualResults['predict_proba'] = model.predict_proba(X_test)\n",
    "    testResults.append(individualResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DOI', 'model_name', 'prediction', 'predict_proba'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testResults[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(526, 12)\n"
     ]
    }
   ],
   "source": [
    "predictionsDF = pd.DataFrame()\n",
    "predictionsDF['DOI'] = testResults[0]['DOI']\n",
    "\n",
    "for i, result in enumerate(testResults):\n",
    "    name = testResults[i]['model_name']\n",
    "    y_hat = '_prediction'\n",
    "    col_name = name+y_hat\n",
    "    predictionsDF[col_name] = testResults[i]['prediction']\n",
    "    y_hat = '_predProba'\n",
    "    col_name = name+y_hat\n",
    "    predictionsDF[col_name] = testResults[i]['predict_proba'][:,1]\n",
    "\n",
    "predictionsDF.index = y_test.index\n",
    "predictionsDF = predictionsDF.join(y_test)\n",
    "#predictionsDF = pd.concat([y_test, predictionsDF.reset_index(drop=True)], axis=1)\n",
    "print(predictionsDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221                    10.7202/032477ar\n",
       "318             10.1073/pnas.1604903113\n",
       "926           10.1016/bs.vh.2022.10.007\n",
       "2489    10.1016/j.scitotenv.2022.153829\n",
       "1420          10.3389/fimmu.2020.559746\n",
       "                     ...               \n",
       "76                  10.1038/nature09077\n",
       "2581       10.1371/journal.pone.0232682\n",
       "620           10.1017/s0033822200000710\n",
       "1151             10.15586/aei.v51i2.796\n",
       "1220             10.1126/sciadv.aay2169\n",
       "Name: DOI, Length: 526, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testResults[1]['DOI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>LogisticRegression_prediction</th>\n",
       "      <th>LogisticRegression_predProba</th>\n",
       "      <th>DecisionTreeClassifier_prediction</th>\n",
       "      <th>DecisionTreeClassifier_predProba</th>\n",
       "      <th>KNeighborsClassifier_prediction</th>\n",
       "      <th>KNeighborsClassifier_predProba</th>\n",
       "      <th>BernoulliNB_prediction</th>\n",
       "      <th>BernoulliNB_predProba</th>\n",
       "      <th>RandomForestClassifier_prediction</th>\n",
       "      <th>RandomForestClassifier_predProba</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>10.7202/032477ar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.314396e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531828</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>10.1073/pnas.1604903113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.669651</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>10.1016/bs.vh.2022.10.007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.184222e-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>10.1016/j.scitotenv.2022.153829</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.418075e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>10.3389/fimmu.2020.559746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.759976e-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10.1038/nature09077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429563</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>10.1371/journal.pone.0232682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.241724e-76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>10.1017/s0033822200000710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.203860e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>10.15586/aei.v51i2.796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.450976e-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>10.1126/sciadv.aay2169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.483034e-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI  LogisticRegression_prediction  \\\n",
       "221                  10.7202/032477ar                            1.0   \n",
       "318           10.1073/pnas.1604903113                            1.0   \n",
       "926         10.1016/bs.vh.2022.10.007                            0.0   \n",
       "2489  10.1016/j.scitotenv.2022.153829                            1.0   \n",
       "1420        10.3389/fimmu.2020.559746                            0.0   \n",
       "...                               ...                            ...   \n",
       "76                10.1038/nature09077                            0.0   \n",
       "2581     10.1371/journal.pone.0232682                            0.0   \n",
       "620         10.1017/s0033822200000710                            1.0   \n",
       "1151           10.15586/aei.v51i2.796                            0.0   \n",
       "1220           10.1126/sciadv.aay2169                            0.0   \n",
       "\n",
       "      LogisticRegression_predProba  DecisionTreeClassifier_prediction  \\\n",
       "221                       0.990222                                1.0   \n",
       "318                       0.951752                                1.0   \n",
       "926                       0.027619                                0.0   \n",
       "2489                      0.956433                                1.0   \n",
       "1420                      0.000758                                0.0   \n",
       "...                            ...                                ...   \n",
       "76                        0.383755                                0.0   \n",
       "2581                      0.094495                                0.0   \n",
       "620                       0.861018                                1.0   \n",
       "1151                      0.114453                                0.0   \n",
       "1220                      0.108305                                0.0   \n",
       "\n",
       "      DecisionTreeClassifier_predProba  KNeighborsClassifier_prediction  \\\n",
       "221                           1.000000                              1.0   \n",
       "318                           1.000000                              1.0   \n",
       "926                           0.134327                              0.0   \n",
       "2489                          0.931151                              1.0   \n",
       "1420                          0.134327                              0.0   \n",
       "...                                ...                              ...   \n",
       "76                            0.421443                              1.0   \n",
       "2581                          0.134327                              0.0   \n",
       "620                           1.000000                              1.0   \n",
       "1151                          0.015799                              0.0   \n",
       "1220                          0.015799                              1.0   \n",
       "\n",
       "      KNeighborsClassifier_predProba  BernoulliNB_prediction  \\\n",
       "221                         0.600000                     0.0   \n",
       "318                         0.933333                     1.0   \n",
       "926                         0.133333                     0.0   \n",
       "2489                        0.600000                     0.0   \n",
       "1420                        0.066667                     0.0   \n",
       "...                              ...                     ...   \n",
       "76                          0.533333                     1.0   \n",
       "2581                        0.266667                     0.0   \n",
       "620                         0.800000                     0.0   \n",
       "1151                        0.066667                     0.0   \n",
       "1220                        0.733333                     0.0   \n",
       "\n",
       "      BernoulliNB_predProba  RandomForestClassifier_prediction  \\\n",
       "221            9.314396e-06                                1.0   \n",
       "318            1.000000e+00                                1.0   \n",
       "926            2.184222e-25                                0.0   \n",
       "2489           3.418075e-18                                0.0   \n",
       "1420           3.759976e-21                                0.0   \n",
       "...                     ...                                ...   \n",
       "76             1.000000e+00                                0.0   \n",
       "2581           5.241724e-76                                0.0   \n",
       "620            2.203860e-02                                1.0   \n",
       "1151           8.450976e-28                                0.0   \n",
       "1220           2.483034e-21                                0.0   \n",
       "\n",
       "      RandomForestClassifier_predProba  target  \n",
       "221                           0.531828     1.0  \n",
       "318                           0.669651     1.0  \n",
       "926                           0.062389     0.0  \n",
       "2489                          0.435171     1.0  \n",
       "1420                          0.172022     0.0  \n",
       "...                                ...     ...  \n",
       "76                            0.429563     1.0  \n",
       "2581                          0.155096     0.0  \n",
       "620                           0.550700     1.0  \n",
       "1151                          0.136614     0.0  \n",
       "1220                          0.285989     0.0  \n",
       "\n",
       "[526 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Reg Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91       348\n",
      "         1.0       0.85      0.78      0.82       178\n",
      "\n",
      "    accuracy                           0.88       526\n",
      "   macro avg       0.87      0.86      0.86       526\n",
      "weighted avg       0.88      0.88      0.88       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep = classification_report(predictionsDF['target'] , predictionsDF['LogisticRegression_prediction'])\n",
    "\n",
    "print(\"Log Reg Classification Report: \\n \", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.83      0.82       348\n",
      "         1.0       0.66      0.63      0.65       178\n",
      "\n",
      "    accuracy                           0.76       526\n",
      "   macro avg       0.74      0.73      0.73       526\n",
      "weighted avg       0.76      0.76      0.76       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep = classification_report(predictionsDF['target'] , predictionsDF['DecisionTreeClassifier_prediction'])\n",
    "\n",
    "print(\"Decision Tree Classification Report: \\n \", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.86      0.86       348\n",
      "         1.0       0.73      0.72      0.72       178\n",
      "\n",
      "    accuracy                           0.81       526\n",
      "   macro avg       0.79      0.79      0.79       526\n",
      "weighted avg       0.81      0.81      0.81       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep = classification_report(predictionsDF['target'] , predictionsDF['KNeighborsClassifier_prediction'])\n",
    "\n",
    "print(\"KNN Classification Report: \\n \", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.64      0.70       348\n",
      "         1.0       0.47      0.63      0.54       178\n",
      "\n",
      "    accuracy                           0.64       526\n",
      "   macro avg       0.62      0.64      0.62       526\n",
      "weighted avg       0.67      0.64      0.65       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep = classification_report(predictionsDF['target'] , predictionsDF['BernoulliNB_prediction'])\n",
    "\n",
    "print(\"Bernoulli NB Classification Report: \\n \", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.97      0.90       348\n",
      "         1.0       0.91      0.65      0.76       178\n",
      "\n",
      "    accuracy                           0.86       526\n",
      "   macro avg       0.88      0.81      0.83       526\n",
      "weighted avg       0.87      0.86      0.85       526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep = classification_report(predictionsDF['target'] , predictionsDF['RandomForestClassifier_prediction'])\n",
    "\n",
    "print(\"Random Forest Classification Report: \\n \", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression_prediction</th>\n",
       "      <th>LogisticRegression_predProba</th>\n",
       "      <th>DecisionTreeClassifier_prediction</th>\n",
       "      <th>DecisionTreeClassifier_predProba</th>\n",
       "      <th>KNeighborsClassifier_prediction</th>\n",
       "      <th>KNeighborsClassifier_predProba</th>\n",
       "      <th>BernoulliNB_prediction</th>\n",
       "      <th>BernoulliNB_predProba</th>\n",
       "      <th>RandomForestClassifier_prediction</th>\n",
       "      <th>RandomForestClassifier_predProba</th>\n",
       "      <th>target</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.314396e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.7202/032477ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1073/pnas.1604903113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.184222e-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1016/bs.vh.2022.10.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956433</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.418075e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1016/j.scitotenv.2022.153829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.759976e-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3389/fimmu.2020.559746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1038/nature09077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.241724e-76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1371/journal.pone.0232682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.203860e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1017/s0033822200000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.450976e-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.15586/aei.v51i2.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.483034e-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1126/sciadv.aay2169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>526 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogisticRegression_prediction  LogisticRegression_predProba  \\\n",
       "221                             1.0                      0.990222   \n",
       "318                             1.0                      0.951752   \n",
       "926                             0.0                      0.027619   \n",
       "2489                            1.0                      0.956433   \n",
       "1420                            0.0                      0.000758   \n",
       "...                             ...                           ...   \n",
       "76                              0.0                      0.383755   \n",
       "2581                            0.0                      0.094495   \n",
       "620                             1.0                      0.861018   \n",
       "1151                            0.0                      0.114453   \n",
       "1220                            0.0                      0.108305   \n",
       "\n",
       "      DecisionTreeClassifier_prediction  DecisionTreeClassifier_predProba  \\\n",
       "221                                 0.0                          0.000000   \n",
       "318                                 1.0                          1.000000   \n",
       "926                                 0.0                          0.134327   \n",
       "2489                                1.0                          0.931151   \n",
       "1420                                0.0                          0.134327   \n",
       "...                                 ...                               ...   \n",
       "76                                  0.0                          0.421443   \n",
       "2581                                0.0                          0.134327   \n",
       "620                                 1.0                          1.000000   \n",
       "1151                                0.0                          0.015799   \n",
       "1220                                0.0                          0.015799   \n",
       "\n",
       "      KNeighborsClassifier_prediction  KNeighborsClassifier_predProba  \\\n",
       "221                               1.0                        0.600000   \n",
       "318                               1.0                        0.933333   \n",
       "926                               0.0                        0.133333   \n",
       "2489                              1.0                        0.600000   \n",
       "1420                              0.0                        0.066667   \n",
       "...                               ...                             ...   \n",
       "76                                1.0                        0.533333   \n",
       "2581                              0.0                        0.266667   \n",
       "620                               1.0                        0.800000   \n",
       "1151                              0.0                        0.066667   \n",
       "1220                              1.0                        0.733333   \n",
       "\n",
       "      BernoulliNB_prediction  BernoulliNB_predProba  \\\n",
       "221                      0.0           9.314396e-06   \n",
       "318                      1.0           1.000000e+00   \n",
       "926                      0.0           2.184222e-25   \n",
       "2489                     0.0           3.418075e-18   \n",
       "1420                     0.0           3.759976e-21   \n",
       "...                      ...                    ...   \n",
       "76                       1.0           1.000000e+00   \n",
       "2581                     0.0           5.241724e-76   \n",
       "620                      0.0           2.203860e-02   \n",
       "1151                     0.0           8.450976e-28   \n",
       "1220                     0.0           2.483034e-21   \n",
       "\n",
       "      RandomForestClassifier_prediction  RandomForestClassifier_predProba  \\\n",
       "221                                 1.0                              0.53   \n",
       "318                                 1.0                              0.68   \n",
       "926                                 0.0                              0.07   \n",
       "2489                                0.0                              0.40   \n",
       "1420                                0.0                              0.11   \n",
       "...                                 ...                               ...   \n",
       "76                                  0.0                              0.41   \n",
       "2581                                0.0                              0.27   \n",
       "620                                 1.0                              0.58   \n",
       "1151                                0.0                              0.13   \n",
       "1220                                0.0                              0.21   \n",
       "\n",
       "      target                              DOI  \n",
       "221      1.0                 10.7202/032477ar  \n",
       "318      1.0          10.1073/pnas.1604903113  \n",
       "926      0.0        10.1016/bs.vh.2022.10.007  \n",
       "2489     1.0  10.1016/j.scitotenv.2022.153829  \n",
       "1420     0.0        10.3389/fimmu.2020.559746  \n",
       "...      ...                              ...  \n",
       "76       1.0              10.1038/nature09077  \n",
       "2581     0.0     10.1371/journal.pone.0232682  \n",
       "620      1.0        10.1017/s0033822200000710  \n",
       "1151     0.0           10.15586/aei.v51i2.796  \n",
       "1220     0.0           10.1126/sciadv.aay2169  \n",
       "\n",
       "[526 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDF.merge(completeDF[['DOI']], left_index=True, right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the Complete X, just for creation of Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "DecisionTreeClassifier\n",
      "KNeighborsClassifier\n",
      "BernoulliNB\n",
      "RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "testResults = list()\n",
    "for counter, model in enumerate(resultsDict['model']):\n",
    "    individualResults = dict()\n",
    "    individualResults['DOI'] = X['DOI']\n",
    "    individualResults['model_name'] = resultsDict['model_name'][counter]\n",
    "    print(resultsDict['model_name'][counter])\n",
    "    individualResults['prediction'] = model.predict(X)\n",
    "    individualResults['predict_proba'] = model.predict_proba(X)\n",
    "    testResults.append(individualResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2629, 771)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "DecisionTreeClassifier\n",
      "KNeighborsClassifier\n",
      "BernoulliNB\n",
      "RandomForestClassifier\n",
      "2629\n"
     ]
    }
   ],
   "source": [
    "predictionsDF = pd.DataFrame()\n",
    "predictionsDF['DOI'] = testResults[0]['DOI']\n",
    "\n",
    "for i, result in enumerate(testResults):\n",
    "    print(testResults[i]['model_name'])\n",
    "    name = testResults[i]['model_name']\n",
    "    y_hat = '_prediction'\n",
    "    col_name = name+y_hat\n",
    "    predictionsDF[col_name] = testResults[i]['prediction']\n",
    "    y_hat = '_predProba'\n",
    "    col_name = name+y_hat\n",
    "    predictionsDF[col_name] = testResults[i]['predict_proba'][:,1]\n",
    "\n",
    "print(predictionsDF.shape[0])\n",
    "\n",
    "predictionsDF.index = y.index\n",
    "predictionsDF = predictionsDF.join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>LogisticRegression_prediction</th>\n",
       "      <th>LogisticRegression_predProba</th>\n",
       "      <th>DecisionTreeClassifier_prediction</th>\n",
       "      <th>DecisionTreeClassifier_predProba</th>\n",
       "      <th>KNeighborsClassifier_prediction</th>\n",
       "      <th>KNeighborsClassifier_predProba</th>\n",
       "      <th>BernoulliNB_prediction</th>\n",
       "      <th>BernoulliNB_predProba</th>\n",
       "      <th>RandomForestClassifier_prediction</th>\n",
       "      <th>RandomForestClassifier_predProba</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1016/j.quascirev.2014.04.014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869580</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1002/gea.10020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666269</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1139/e80-122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915013</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               DOI  LogisticRegression_prediction  \\\n",
       "0  10.1016/j.quascirev.2014.04.014                            1.0   \n",
       "1                10.1002/gea.10020                            1.0   \n",
       "2                  10.1139/e80-122                            1.0   \n",
       "\n",
       "   LogisticRegression_predProba  DecisionTreeClassifier_prediction  \\\n",
       "0                      0.994494                                1.0   \n",
       "1                      0.551270                                0.0   \n",
       "2                      0.998998                                1.0   \n",
       "\n",
       "   DecisionTreeClassifier_predProba  KNeighborsClassifier_prediction  \\\n",
       "0                          0.934448                              1.0   \n",
       "1                          0.320705                              0.0   \n",
       "2                          0.931151                              1.0   \n",
       "\n",
       "   KNeighborsClassifier_predProba  BernoulliNB_prediction  \\\n",
       "0                        0.733333                     1.0   \n",
       "1                        0.400000                     1.0   \n",
       "2                        1.000000                     1.0   \n",
       "\n",
       "   BernoulliNB_predProba  RandomForestClassifier_prediction  \\\n",
       "0               1.000000                                1.0   \n",
       "1               0.998807                                1.0   \n",
       "2               0.999786                                1.0   \n",
       "\n",
       "   RandomForestClassifier_predProba  target  \n",
       "0                          0.869580     1.0  \n",
       "1                          0.666269     1.0  \n",
       "2                          0.915013     1.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression_prediction</th>\n",
       "      <th>LogisticRegression_predProba</th>\n",
       "      <th>DecisionTreeClassifier_prediction</th>\n",
       "      <th>DecisionTreeClassifier_predProba</th>\n",
       "      <th>KNeighborsClassifier_prediction</th>\n",
       "      <th>KNeighborsClassifier_predProba</th>\n",
       "      <th>BernoulliNB_prediction</th>\n",
       "      <th>BernoulliNB_predProba</th>\n",
       "      <th>RandomForestClassifier_prediction</th>\n",
       "      <th>RandomForestClassifier_predProba</th>\n",
       "      <th>target</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1016/j.quascirev.2014.04.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.988071e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1002/gea.10020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.997864e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1139/e80-122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.981018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1016/j.quaint.2015.05.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.980496e-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.1191/0959683604hl761rp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.938330e-79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3390/genes12030432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.241724e-76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1371/journal.pone.0211990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.934267e-76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1371/journal.pbio.3000764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523840e-75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1007/s11356-022-19414-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.410336e-75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1540/jsmr.59.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2629 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LogisticRegression_prediction  LogisticRegression_predProba  \\\n",
       "0                               1.0                      0.994494   \n",
       "1                               1.0                      0.551270   \n",
       "2                               1.0                      0.998998   \n",
       "3                               1.0                      0.981018   \n",
       "4                               1.0                      0.990198   \n",
       "...                             ...                           ...   \n",
       "2624                            0.0                      0.064652   \n",
       "2625                            0.0                      0.094495   \n",
       "2626                            0.0                      0.089111   \n",
       "2627                            0.0                      0.158769   \n",
       "2628                            0.0                      0.123702   \n",
       "\n",
       "      DecisionTreeClassifier_prediction  DecisionTreeClassifier_predProba  \\\n",
       "0                                   1.0                          0.934448   \n",
       "1                                   0.0                          0.320705   \n",
       "2                                   1.0                          0.931151   \n",
       "3                                   1.0                          0.934448   \n",
       "4                                   1.0                          0.931151   \n",
       "...                                 ...                               ...   \n",
       "2624                                0.0                          0.134327   \n",
       "2625                                0.0                          0.134327   \n",
       "2626                                0.0                          0.134327   \n",
       "2627                                0.0                          0.134327   \n",
       "2628                                0.0                          0.134327   \n",
       "\n",
       "      KNeighborsClassifier_prediction  KNeighborsClassifier_predProba  \\\n",
       "0                                 1.0                        0.733333   \n",
       "1                                 0.0                        0.400000   \n",
       "2                                 1.0                        1.000000   \n",
       "3                                 1.0                        0.866667   \n",
       "4                                 1.0                        0.866667   \n",
       "...                               ...                             ...   \n",
       "2624                              0.0                        0.200000   \n",
       "2625                              0.0                        0.266667   \n",
       "2626                              0.0                        0.266667   \n",
       "2627                              0.0                        0.133333   \n",
       "2628                              0.0                        0.133333   \n",
       "\n",
       "      BernoulliNB_prediction  BernoulliNB_predProba  \\\n",
       "0                        1.0           1.000000e+00   \n",
       "1                        1.0           9.988071e-01   \n",
       "2                        1.0           9.997864e-01   \n",
       "3                        1.0           1.000000e+00   \n",
       "4                        1.0           9.980496e-01   \n",
       "...                      ...                    ...   \n",
       "2624                     0.0           6.938330e-79   \n",
       "2625                     0.0           5.241724e-76   \n",
       "2626                     0.0           4.934267e-76   \n",
       "2627                     0.0           1.523840e-75   \n",
       "2628                     0.0           7.410336e-75   \n",
       "\n",
       "      RandomForestClassifier_prediction  RandomForestClassifier_predProba  \\\n",
       "0                                   1.0                              0.89   \n",
       "1                                   1.0                              0.72   \n",
       "2                                   1.0                              0.87   \n",
       "3                                   1.0                              0.92   \n",
       "4                                   1.0                              0.94   \n",
       "...                                 ...                               ...   \n",
       "2624                                0.0                              0.13   \n",
       "2625                                0.0                              0.27   \n",
       "2626                                0.0                              0.16   \n",
       "2627                                0.0                              0.00   \n",
       "2628                                0.0                              0.10   \n",
       "\n",
       "      target                              DOI  \n",
       "0        1.0  10.1016/j.quascirev.2014.04.014  \n",
       "1        1.0                10.1002/gea.10020  \n",
       "2        1.0                  10.1139/e80-122  \n",
       "3        1.0     10.1016/j.quaint.2015.05.009  \n",
       "4        1.0        10.1191/0959683604hl761rp  \n",
       "...      ...                              ...  \n",
       "2624     0.0            10.3390/genes12030432  \n",
       "2625     0.0     10.1371/journal.pone.0211990  \n",
       "2626     0.0     10.1371/journal.pbio.3000764  \n",
       "2627     0.0       10.1007/s11356-022-19414-5  \n",
       "2628     0.0               10.1540/jsmr.59.28  \n",
       "\n",
       "[2629 rows x 12 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictionsDF.merge(completeDF[['DOI']], left_index=True, right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF.to_parquet('data/parquet/neotomaPredictions.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DOI', 'LogisticRegression_prediction', 'LogisticRegression_predProba',\n",
       "       'DecisionTreeClassifier_prediction', 'DecisionTreeClassifier_predProba',\n",
       "       'KNeighborsClassifier_prediction', 'KNeighborsClassifier_predProba',\n",
       "       'BernoulliNB_prediction', 'BernoulliNB_predProba',\n",
       "       'RandomForestClassifier_prediction', 'RandomForestClassifier_predProba',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "my_dict = joblib.load('/Users/sedv8808/HT-Data/UWisc/article-relevance/results/Iteration_2023-10-10_11-17-37.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': ['LogisticRegression',\n",
       "  'DecisionTreeClassifier',\n",
       "  'KNeighborsClassifier',\n",
       "  'BernoulliNB',\n",
       "  'RandomForestClassifier'],\n",
       " 'model': [Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(remainder='passthrough',\n",
       "                                     transformers=[('str_preprocessor',\n",
       "                                                    CountVectorizer(max_features=100,\n",
       "                                                                    stop_words=['i',\n",
       "                                                                                'me',\n",
       "                                                                                'my',\n",
       "                                                                                'myself',\n",
       "                                                                                'we',\n",
       "                                                                                'our',\n",
       "                                                                                'ours',\n",
       "                                                                                'ourselves',\n",
       "                                                                                'you',\n",
       "                                                                                \"you're\",\n",
       "                                                                                \"you've\",\n",
       "                                                                                \"you'll\",\n",
       "                                                                                \"you'd\",\n",
       "                                                                                'your',\n",
       "                                                                                'yours',\n",
       "                                                                                'yourself',\n",
       "                                                                                'yourselves',\n",
       "                                                                                'he',\n",
       "                                                                                'him',\n",
       "                                                                                'his',\n",
       "                                                                                'himself',\n",
       "                                                                                'she',\n",
       "                                                                                \"she's\",\n",
       "                                                                                'her',\n",
       "                                                                                'hers',\n",
       "                                                                                'herself',\n",
       "                                                                                'it',\n",
       "                                                                                \"it's\",\n",
       "                                                                                'its',\n",
       "                                                                                'itself', ...]),\n",
       "                                                    'container-title'),\n",
       "                                                   ('neotoma_encoder',\n",
       "                                                    NeotomaOneHotEncoder(min_count=10),\n",
       "                                                    ['subject',\n",
       "                                                     'container-title'])])),\n",
       "                  ('simpleimputer',\n",
       "                   SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                  ('logisticregression', LogisticRegression(C=1, max_iter=1000))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(remainder='passthrough',\n",
       "                                     transformers=[('str_preprocessor',\n",
       "                                                    CountVectorizer(max_features=100,\n",
       "                                                                    stop_words=['i',\n",
       "                                                                                'me',\n",
       "                                                                                'my',\n",
       "                                                                                'myself',\n",
       "                                                                                'we',\n",
       "                                                                                'our',\n",
       "                                                                                'ours',\n",
       "                                                                                'ourselves',\n",
       "                                                                                'you',\n",
       "                                                                                \"you're\",\n",
       "                                                                                \"you've\",\n",
       "                                                                                \"you'll\",\n",
       "                                                                                \"you'd\",\n",
       "                                                                                'your',\n",
       "                                                                                'yours',\n",
       "                                                                                'yourself',\n",
       "                                                                                'yourselves',\n",
       "                                                                                'he',\n",
       "                                                                                'him',\n",
       "                                                                                'his',\n",
       "                                                                                'himself',\n",
       "                                                                                'she',\n",
       "                                                                                \"she's\",\n",
       "                                                                                'her',\n",
       "                                                                                'hers',\n",
       "                                                                                'herself',\n",
       "                                                                                'it',\n",
       "                                                                                \"it's\",\n",
       "                                                                                'its',\n",
       "                                                                                'itself', ...]),\n",
       "                                                    'container-title'),\n",
       "                                                   ('neotoma_encoder',\n",
       "                                                    NeotomaOneHotEncoder(min_count=10),\n",
       "                                                    ['subject',\n",
       "                                                     'container-title'])])),\n",
       "                  ('simpleimputer',\n",
       "                   SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                  ('decisiontreeclassifier',\n",
       "                   DecisionTreeClassifier(class_weight='balanced',\n",
       "                                          max_depth=10))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(remainder='passthrough',\n",
       "                                     transformers=[('str_preprocessor',\n",
       "                                                    CountVectorizer(max_features=100,\n",
       "                                                                    stop_words=['i',\n",
       "                                                                                'me',\n",
       "                                                                                'my',\n",
       "                                                                                'myself',\n",
       "                                                                                'we',\n",
       "                                                                                'our',\n",
       "                                                                                'ours',\n",
       "                                                                                'ourselves',\n",
       "                                                                                'you',\n",
       "                                                                                \"you're\",\n",
       "                                                                                \"you've\",\n",
       "                                                                                \"you'll\",\n",
       "                                                                                \"you'd\",\n",
       "                                                                                'your',\n",
       "                                                                                'yours',\n",
       "                                                                                'yourself',\n",
       "                                                                                'yourselves',\n",
       "                                                                                'he',\n",
       "                                                                                'him',\n",
       "                                                                                'his',\n",
       "                                                                                'himself',\n",
       "                                                                                'she',\n",
       "                                                                                \"she's\",\n",
       "                                                                                'her',\n",
       "                                                                                'hers',\n",
       "                                                                                'herself',\n",
       "                                                                                'it',\n",
       "                                                                                \"it's\",\n",
       "                                                                                'its',\n",
       "                                                                                'itself', ...]),\n",
       "                                                    'container-title'),\n",
       "                                                   ('neotoma_encoder',\n",
       "                                                    NeotomaOneHotEncoder(min_count=10),\n",
       "                                                    ['subject',\n",
       "                                                     'container-title'])])),\n",
       "                  ('simpleimputer',\n",
       "                   SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                  ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=15))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(remainder='passthrough',\n",
       "                                     transformers=[('str_preprocessor',\n",
       "                                                    CountVectorizer(max_features=100,\n",
       "                                                                    stop_words=['i',\n",
       "                                                                                'me',\n",
       "                                                                                'my',\n",
       "                                                                                'myself',\n",
       "                                                                                'we',\n",
       "                                                                                'our',\n",
       "                                                                                'ours',\n",
       "                                                                                'ourselves',\n",
       "                                                                                'you',\n",
       "                                                                                \"you're\",\n",
       "                                                                                \"you've\",\n",
       "                                                                                \"you'll\",\n",
       "                                                                                \"you'd\",\n",
       "                                                                                'your',\n",
       "                                                                                'yours',\n",
       "                                                                                'yourself',\n",
       "                                                                                'yourselves',\n",
       "                                                                                'he',\n",
       "                                                                                'him',\n",
       "                                                                                'his',\n",
       "                                                                                'himself',\n",
       "                                                                                'she',\n",
       "                                                                                \"she's\",\n",
       "                                                                                'her',\n",
       "                                                                                'hers',\n",
       "                                                                                'herself',\n",
       "                                                                                'it',\n",
       "                                                                                \"it's\",\n",
       "                                                                                'its',\n",
       "                                                                                'itself', ...]),\n",
       "                                                    'container-title'),\n",
       "                                                   ('neotoma_encoder',\n",
       "                                                    NeotomaOneHotEncoder(min_count=10),\n",
       "                                                    ['subject',\n",
       "                                                     'container-title'])])),\n",
       "                  ('simpleimputer',\n",
       "                   SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                  ('bernoullinb', BernoulliNB(alpha=0.001))]),\n",
       "  Pipeline(steps=[('columntransformer',\n",
       "                   ColumnTransformer(remainder='passthrough',\n",
       "                                     transformers=[('str_preprocessor',\n",
       "                                                    CountVectorizer(max_features=100,\n",
       "                                                                    stop_words=['i',\n",
       "                                                                                'me',\n",
       "                                                                                'my',\n",
       "                                                                                'myself',\n",
       "                                                                                'we',\n",
       "                                                                                'our',\n",
       "                                                                                'ours',\n",
       "                                                                                'ourselves',\n",
       "                                                                                'you',\n",
       "                                                                                \"you're\",\n",
       "                                                                                \"you've\",\n",
       "                                                                                \"you'll\",\n",
       "                                                                                \"you'd\",\n",
       "                                                                                'your',\n",
       "                                                                                'yours',\n",
       "                                                                                'yourself',\n",
       "                                                                                'yourselves',\n",
       "                                                                                'he',\n",
       "                                                                                'him',\n",
       "                                                                                'his',\n",
       "                                                                                'himself',\n",
       "                                                                                'she',\n",
       "                                                                                \"she's\",\n",
       "                                                                                'her',\n",
       "                                                                                'hers',\n",
       "                                                                                'herself',\n",
       "                                                                                'it',\n",
       "                                                                                \"it's\",\n",
       "                                                                                'its',\n",
       "                                                                                'itself', ...]),\n",
       "                                                    'container-title'),\n",
       "                                                   ('neotoma_encoder',\n",
       "                                                    NeotomaOneHotEncoder(min_count=10),\n",
       "                                                    ['subject',\n",
       "                                                     'container-title'])])),\n",
       "                  ('simpleimputer',\n",
       "                   SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                  ('randomforestclassifier', RandomForestClassifier())])],\n",
       " 'report': [{'classifier': ['LogisticRegression',\n",
       "    'DecisionTreeClassifier',\n",
       "    'KNeighborsClassifier',\n",
       "    'BernoulliNB',\n",
       "    'RandomForestClassifier'],\n",
       "   'Fit Time': [datetime.timedelta(seconds=31, microseconds=85787),\n",
       "    datetime.timedelta(seconds=43, microseconds=942452),\n",
       "    datetime.timedelta(seconds=24, microseconds=852635),\n",
       "    datetime.timedelta(seconds=11, microseconds=834530),\n",
       "    datetime.timedelta(seconds=82, microseconds=419802)],\n",
       "   'train_recall': [0.8827133324324498,\n",
       "    0.9221791085114187,\n",
       "    0.7453433974891089,\n",
       "    0.7292072868606141,\n",
       "    1.0],\n",
       "   'train_f1': [0.9290245071231624,\n",
       "    0.9166238498216931,\n",
       "    0.7406612668708946,\n",
       "    0.5792429734212079,\n",
       "    0.9998209489704566],\n",
       "   'train_precision': [0.9804951557692407,\n",
       "    0.9119517133867658,\n",
       "    0.7361372034833796,\n",
       "    0.48047606808465426,\n",
       "    0.9996422182468694],\n",
       "   'train_accuracy': [0.9553019881970013,\n",
       "    0.944483090681594,\n",
       "    0.8270329369091346,\n",
       "    0.648955668456263,\n",
       "    0.999881164587047],\n",
       "   'test_recall': [0.7402980472764644,\n",
       "    0.6399897225077081,\n",
       "    0.7001541623843781,\n",
       "    0.710082219938335,\n",
       "    0.6211408016443988],\n",
       "   'test_f1': [0.7788166747957469,\n",
       "    0.6244442581813096,\n",
       "    0.6878111740479184,\n",
       "    0.5688625363373115,\n",
       "    0.7067853140310388],\n",
       "   'test_precision': [0.8219061678694464,\n",
       "    0.6126652073162401,\n",
       "    0.6762395204513933,\n",
       "    0.4748444968129693,\n",
       "    0.8221222445265592],\n",
       "   'test_accuracy': [0.8606752629793011,\n",
       "    0.7456271914941748,\n",
       "    0.789345096708517,\n",
       "    0.6438264902160389,\n",
       "    0.8297556837461826]}],\n",
       " 'date': [datetime.datetime(2023, 10, 10, 11, 19, 0, 46192)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_name', 'model', 'report', 'date'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sedv8808/HT-Data/UWisc/article-relevance/Training_model.ipynb Cell 61\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sedv8808/HT-Data/UWisc/article-relevance/Training_model.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(my_dict[\u001b[39m'\u001b[39m\u001b[39mreport\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(my_dict['report'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;str_preprocessor&#x27;,\n",
       "                                                  CountVectorizer(max_features=100,\n",
       "                                                                  stop_words=[&#x27;i&#x27;,\n",
       "                                                                              &#x27;me&#x27;,\n",
       "                                                                              &#x27;my&#x27;,\n",
       "                                                                              &#x27;myself&#x27;,\n",
       "                                                                              &#x27;we&#x27;,\n",
       "                                                                              &#x27;our&#x27;,\n",
       "                                                                              &#x27;ours&#x27;,\n",
       "                                                                              &#x27;ourselves&#x27;,\n",
       "                                                                              &#x27;you&#x27;,\n",
       "                                                                              &quot;you&#x27;re&quot;,\n",
       "                                                                              &quot;you&#x27;ve&quot;,\n",
       "                                                                              &quot;you&#x27;ll&quot;,\n",
       "                                                                              &quot;you&#x27;d&quot;,\n",
       "                                                                              &#x27;your&#x27;,\n",
       "                                                                              &#x27;yours&#x27;,\n",
       "                                                                              &#x27;yourself&#x27;,\n",
       "                                                                              &#x27;yourselves&#x27;,\n",
       "                                                                              &#x27;he&#x27;,\n",
       "                                                                              &#x27;him&#x27;,\n",
       "                                                                              &#x27;his&#x27;,\n",
       "                                                                              &#x27;himself&#x27;,\n",
       "                                                                              &#x27;she&#x27;,\n",
       "                                                                              &quot;she&#x27;s&quot;,\n",
       "                                                                              &#x27;her&#x27;,\n",
       "                                                                              &#x27;hers&#x27;,\n",
       "                                                                              &#x27;herself&#x27;,\n",
       "                                                                              &#x27;it&#x27;,\n",
       "                                                                              &quot;it&#x27;s&quot;,\n",
       "                                                                              &#x27;its&#x27;,\n",
       "                                                                              &#x27;itself&#x27;, ...]),\n",
       "                                                  &#x27;container-title&#x27;),\n",
       "                                                 (&#x27;neotoma_encoder&#x27;,\n",
       "                                                  NeotomaOneHotEncoder(min_count=10),\n",
       "                                                  [&#x27;subject&#x27;,\n",
       "                                                   &#x27;container-title&#x27;])])),\n",
       "                (&#x27;simpleimputer&#x27;,\n",
       "                 SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(C=1, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;str_preprocessor&#x27;,\n",
       "                                                  CountVectorizer(max_features=100,\n",
       "                                                                  stop_words=[&#x27;i&#x27;,\n",
       "                                                                              &#x27;me&#x27;,\n",
       "                                                                              &#x27;my&#x27;,\n",
       "                                                                              &#x27;myself&#x27;,\n",
       "                                                                              &#x27;we&#x27;,\n",
       "                                                                              &#x27;our&#x27;,\n",
       "                                                                              &#x27;ours&#x27;,\n",
       "                                                                              &#x27;ourselves&#x27;,\n",
       "                                                                              &#x27;you&#x27;,\n",
       "                                                                              &quot;you&#x27;re&quot;,\n",
       "                                                                              &quot;you&#x27;ve&quot;,\n",
       "                                                                              &quot;you&#x27;ll&quot;,\n",
       "                                                                              &quot;you&#x27;d&quot;,\n",
       "                                                                              &#x27;your&#x27;,\n",
       "                                                                              &#x27;yours&#x27;,\n",
       "                                                                              &#x27;yourself&#x27;,\n",
       "                                                                              &#x27;yourselves&#x27;,\n",
       "                                                                              &#x27;he&#x27;,\n",
       "                                                                              &#x27;him&#x27;,\n",
       "                                                                              &#x27;his&#x27;,\n",
       "                                                                              &#x27;himself&#x27;,\n",
       "                                                                              &#x27;she&#x27;,\n",
       "                                                                              &quot;she&#x27;s&quot;,\n",
       "                                                                              &#x27;her&#x27;,\n",
       "                                                                              &#x27;hers&#x27;,\n",
       "                                                                              &#x27;herself&#x27;,\n",
       "                                                                              &#x27;it&#x27;,\n",
       "                                                                              &quot;it&#x27;s&quot;,\n",
       "                                                                              &#x27;its&#x27;,\n",
       "                                                                              &#x27;itself&#x27;, ...]),\n",
       "                                                  &#x27;container-title&#x27;),\n",
       "                                                 (&#x27;neotoma_encoder&#x27;,\n",
       "                                                  NeotomaOneHotEncoder(min_count=10),\n",
       "                                                  [&#x27;subject&#x27;,\n",
       "                                                   &#x27;container-title&#x27;])])),\n",
       "                (&#x27;simpleimputer&#x27;,\n",
       "                 SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression(C=1, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;str_preprocessor&#x27;,\n",
       "                                 CountVectorizer(max_features=100,\n",
       "                                                 stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;,\n",
       "                                                             &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                                             &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                                                             &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                                             &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;,\n",
       "                                                             &quot;you&#x27;ll&quot;, &quot;you&#x27;d&quot;,\n",
       "                                                             &#x27;your&#x27;, &#x27;yours&#x27;,\n",
       "                                                             &#x27;yourself&#x27;,\n",
       "                                                             &#x27;yourselves&#x27;, &#x27;he&#x27;,\n",
       "                                                             &#x27;him&#x27;, &#x27;his&#x27;,\n",
       "                                                             &#x27;himself&#x27;, &#x27;she&#x27;,\n",
       "                                                             &quot;she&#x27;s&quot;, &#x27;her&#x27;,\n",
       "                                                             &#x27;hers&#x27;, &#x27;herself&#x27;,\n",
       "                                                             &#x27;it&#x27;, &quot;it&#x27;s&quot;,\n",
       "                                                             &#x27;its&#x27;, &#x27;itself&#x27;, ...]),\n",
       "                                 &#x27;container-title&#x27;),\n",
       "                                (&#x27;neotoma_encoder&#x27;,\n",
       "                                 NeotomaOneHotEncoder(min_count=10),\n",
       "                                 [&#x27;subject&#x27;, &#x27;container-title&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">str_preprocessor</label><div class=\"sk-toggleable__content\"><pre>container-title</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=100,\n",
       "                stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">neotoma_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;subject&#x27;, &#x27;container-title&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeotomaOneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>NeotomaOneHotEncoder(min_count=10)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;embedding_0&#x27;, &#x27;embedding_1&#x27;, &#x27;embedding_2&#x27;, &#x27;embedding_3&#x27;, &#x27;embedding_4&#x27;, &#x27;embedding_5&#x27;, &#x27;embedding_6&#x27;, &#x27;embedding_7&#x27;, &#x27;embedding_8&#x27;, &#x27;embedding_9&#x27;, &#x27;embedding_10&#x27;, &#x27;embedding_11&#x27;, &#x27;embedding_12&#x27;, &#x27;embedding_13&#x27;, &#x27;embedding_14&#x27;, &#x27;embedding_15&#x27;, &#x27;embedding_16&#x27;, &#x27;embedding_17&#x27;, &#x27;embedding_18&#x27;, &#x27;embedding_19&#x27;, &#x27;embedding_20&#x27;, &#x27;embedding_21&#x27;, &#x27;embedding_22&#x27;, &#x27;embedding_23&#x27;, &#x27;embedding_24&#x27;, &#x27;embedding_25&#x27;, &#x27;embedding_26&#x27;, &#x27;embedding_27&#x27;, &#x27;embedding_28&#x27;, &#x27;embedding_29&#x27;, &#x27;embedding_30&#x27;, &#x27;embedding_31&#x27;, &#x27;embedding_32&#x27;, &#x27;embedding_33&#x27;, &#x27;embedding_34&#x27;, &#x27;embedding_35&#x27;, &#x27;embedding_36&#x27;, &#x27;embedding_37&#x27;, &#x27;embedding_38&#x27;, &#x27;embedding_39&#x27;, &#x27;embedding_40&#x27;, &#x27;embedding_41&#x27;, &#x27;embedding_42&#x27;, &#x27;embedding_43&#x27;, &#x27;embedding_44&#x27;, &#x27;embedding_45&#x27;, &#x27;embedding_46&#x27;, &#x27;embedding_47&#x27;, &#x27;embedding_48&#x27;, &#x27;embedding_49&#x27;, &#x27;embedding_50&#x27;, &#x27;embedding_51&#x27;, &#x27;embedding_52&#x27;, &#x27;embedding_53&#x27;, &#x27;embedding_54&#x27;, &#x27;embedding_55&#x27;, &#x27;embedding_56&#x27;, &#x27;embedding_57&#x27;, &#x27;embedding_58&#x27;, &#x27;embedding_59&#x27;, &#x27;embedding_60&#x27;, &#x27;embedding_61&#x27;, &#x27;embedding_62&#x27;, &#x27;embedding_63&#x27;, &#x27;embedding_64&#x27;, &#x27;embedding_65&#x27;, &#x27;embedding_66&#x27;, &#x27;embedding_67&#x27;, &#x27;embedding_68&#x27;, &#x27;embedding_69&#x27;, &#x27;embedding_70&#x27;, &#x27;embedding_71&#x27;, &#x27;embedding_72&#x27;, &#x27;embedding_73&#x27;, &#x27;embedding_74&#x27;, &#x27;embedding_75&#x27;, &#x27;embedding_76&#x27;, &#x27;embedding_77&#x27;, &#x27;embedding_78&#x27;, &#x27;embedding_79&#x27;, &#x27;embedding_80&#x27;, &#x27;embedding_81&#x27;, &#x27;embedding_82&#x27;, &#x27;embedding_83&#x27;, &#x27;embedding_84&#x27;, &#x27;embedding_85&#x27;, &#x27;embedding_86&#x27;, &#x27;embedding_87&#x27;, &#x27;embedding_88&#x27;, &#x27;embedding_89&#x27;, &#x27;embedding_90&#x27;, &#x27;embedding_91&#x27;, &#x27;embedding_92&#x27;, &#x27;embedding_93&#x27;, &#x27;embedding_94&#x27;, &#x27;embedding_95&#x27;, &#x27;embedding_96&#x27;, &#x27;embedding_97&#x27;, &#x27;embedding_98&#x27;, &#x27;embedding_99&#x27;, &#x27;embedding_100&#x27;, &#x27;embedding_101&#x27;, &#x27;embedding_102&#x27;, &#x27;embedding_103&#x27;, &#x27;embedding_104&#x27;, &#x27;embedding_105&#x27;, &#x27;embedding_106&#x27;, &#x27;embedding_107&#x27;, &#x27;embedding_108&#x27;, &#x27;embedding_109&#x27;, &#x27;embedding_110&#x27;, &#x27;embedding_111&#x27;, &#x27;embedding_112&#x27;, &#x27;embedding_113&#x27;, &#x27;embedding_114&#x27;, &#x27;embedding_115&#x27;, &#x27;embedding_116&#x27;, &#x27;embedding_117&#x27;, &#x27;embedding_118&#x27;, &#x27;embedding_119&#x27;, &#x27;embedding_120&#x27;, &#x27;embedding_121&#x27;, &#x27;embedding_122&#x27;, &#x27;embedding_123&#x27;, &#x27;embedding_124&#x27;, &#x27;embedding_125&#x27;, &#x27;embedding_126&#x27;, &#x27;embedding_127&#x27;, &#x27;embedding_128&#x27;, &#x27;embedding_129&#x27;, &#x27;embedding_130&#x27;, &#x27;embedding_131&#x27;, &#x27;embedding_132&#x27;, &#x27;embedding_133&#x27;, &#x27;embedding_134&#x27;, &#x27;embedding_135&#x27;, &#x27;embedding_136&#x27;, &#x27;embedding_137&#x27;, &#x27;embedding_138&#x27;, &#x27;embedding_139&#x27;, &#x27;embedding_140&#x27;, &#x27;embedding_141&#x27;, &#x27;embedding_142&#x27;, &#x27;embedding_143&#x27;, &#x27;embedding_144&#x27;, &#x27;embedding_145&#x27;, &#x27;embedding_146&#x27;, &#x27;embedding_147&#x27;, &#x27;embedding_148&#x27;, &#x27;embedding_149&#x27;, &#x27;embedding_150&#x27;, &#x27;embedding_151&#x27;, &#x27;embedding_152&#x27;, &#x27;embedding_153&#x27;, &#x27;embedding_154&#x27;, &#x27;embedding_155&#x27;, &#x27;embedding_156&#x27;, &#x27;embedding_157&#x27;, &#x27;embedding_158&#x27;, &#x27;embedding_159&#x27;, &#x27;embedding_160&#x27;, &#x27;embedding_161&#x27;, &#x27;embedding_162&#x27;, &#x27;embedding_163&#x27;, &#x27;embedding_164&#x27;, &#x27;embedding_165&#x27;, &#x27;embedding_166&#x27;, &#x27;embedding_167&#x27;, &#x27;embedding_168&#x27;, &#x27;embedding_169&#x27;, &#x27;embedding_170&#x27;, &#x27;embedding_171&#x27;, &#x27;embedding_172&#x27;, &#x27;embedding_173&#x27;, &#x27;embedding_174&#x27;, &#x27;embedding_175&#x27;, &#x27;embedding_176&#x27;, &#x27;embedding_177&#x27;, &#x27;embedding_178&#x27;, &#x27;embedding_179&#x27;, &#x27;embedding_180&#x27;, &#x27;embedding_181&#x27;, &#x27;embedding_182&#x27;, &#x27;embedding_183&#x27;, &#x27;embedding_184&#x27;, &#x27;embedding_185&#x27;, &#x27;embedding_186&#x27;, &#x27;embedding_187&#x27;, &#x27;embedding_188&#x27;, &#x27;embedding_189&#x27;, &#x27;embedding_190&#x27;, &#x27;embedding_191&#x27;, &#x27;embedding_192&#x27;, &#x27;embedding_193&#x27;, &#x27;embedding_194&#x27;, &#x27;embedding_195&#x27;, &#x27;embedding_196&#x27;, &#x27;embedding_197&#x27;, &#x27;embedding_198&#x27;, &#x27;embedding_199&#x27;, &#x27;embedding_200&#x27;, &#x27;embedding_201&#x27;, &#x27;embedding_202&#x27;, &#x27;embedding_203&#x27;, &#x27;embedding_204&#x27;, &#x27;embedding_205&#x27;, &#x27;embedding_206&#x27;, &#x27;embedding_207&#x27;, &#x27;embedding_208&#x27;, &#x27;embedding_209&#x27;, &#x27;embedding_210&#x27;, &#x27;embedding_211&#x27;, &#x27;embedding_212&#x27;, &#x27;embedding_213&#x27;, &#x27;embedding_214&#x27;, &#x27;embedding_215&#x27;, &#x27;embedding_216&#x27;, &#x27;embedding_217&#x27;, &#x27;embedding_218&#x27;, &#x27;embedding_219&#x27;, &#x27;embedding_220&#x27;, &#x27;embedding_221&#x27;, &#x27;embedding_222&#x27;, &#x27;embedding_223&#x27;, &#x27;embedding_224&#x27;, &#x27;embedding_225&#x27;, &#x27;embedding_226&#x27;, &#x27;embedding_227&#x27;, &#x27;embedding_228&#x27;, &#x27;embedding_229&#x27;, &#x27;embedding_230&#x27;, &#x27;embedding_231&#x27;, &#x27;embedding_232&#x27;, &#x27;embedding_233&#x27;, &#x27;embedding_234&#x27;, &#x27;embedding_235&#x27;, &#x27;embedding_236&#x27;, &#x27;embedding_237&#x27;, &#x27;embedding_238&#x27;, &#x27;embedding_239&#x27;, &#x27;embedding_240&#x27;, &#x27;embedding_241&#x27;, &#x27;embedding_242&#x27;, &#x27;embedding_243&#x27;, &#x27;embedding_244&#x27;, &#x27;embedding_245&#x27;, &#x27;embedding_246&#x27;, &#x27;embedding_247&#x27;, &#x27;embedding_248&#x27;, &#x27;embedding_249&#x27;, &#x27;embedding_250&#x27;, &#x27;embedding_251&#x27;, &#x27;embedding_252&#x27;, &#x27;embedding_253&#x27;, &#x27;embedding_254&#x27;, &#x27;embedding_255&#x27;, &#x27;embedding_256&#x27;, &#x27;embedding_257&#x27;, &#x27;embedding_258&#x27;, &#x27;embedding_259&#x27;, &#x27;embedding_260&#x27;, &#x27;embedding_261&#x27;, &#x27;embedding_262&#x27;, &#x27;embedding_263&#x27;, &#x27;embedding_264&#x27;, &#x27;embedding_265&#x27;, &#x27;embedding_266&#x27;, &#x27;embedding_267&#x27;, &#x27;embedding_268&#x27;, &#x27;embedding_269&#x27;, &#x27;embedding_270&#x27;, &#x27;embedding_271&#x27;, &#x27;embedding_272&#x27;, &#x27;embedding_273&#x27;, &#x27;embedding_274&#x27;, &#x27;embedding_275&#x27;, &#x27;embedding_276&#x27;, &#x27;embedding_277&#x27;, &#x27;embedding_278&#x27;, &#x27;embedding_279&#x27;, &#x27;embedding_280&#x27;, &#x27;embedding_281&#x27;, &#x27;embedding_282&#x27;, &#x27;embedding_283&#x27;, &#x27;embedding_284&#x27;, &#x27;embedding_285&#x27;, &#x27;embedding_286&#x27;, &#x27;embedding_287&#x27;, &#x27;embedding_288&#x27;, &#x27;embedding_289&#x27;, &#x27;embedding_290&#x27;, &#x27;embedding_291&#x27;, &#x27;embedding_292&#x27;, &#x27;embedding_293&#x27;, &#x27;embedding_294&#x27;, &#x27;embedding_295&#x27;, &#x27;embedding_296&#x27;, &#x27;embedding_297&#x27;, &#x27;embedding_298&#x27;, &#x27;embedding_299&#x27;, &#x27;embedding_300&#x27;, &#x27;embedding_301&#x27;, &#x27;embedding_302&#x27;, &#x27;embedding_303&#x27;, &#x27;embedding_304&#x27;, &#x27;embedding_305&#x27;, &#x27;embedding_306&#x27;, &#x27;embedding_307&#x27;, &#x27;embedding_308&#x27;, &#x27;embedding_309&#x27;, &#x27;embedding_310&#x27;, &#x27;embedding_311&#x27;, &#x27;embedding_312&#x27;, &#x27;embedding_313&#x27;, &#x27;embedding_314&#x27;, &#x27;embedding_315&#x27;, &#x27;embedding_316&#x27;, &#x27;embedding_317&#x27;, &#x27;embedding_318&#x27;, &#x27;embedding_319&#x27;, &#x27;embedding_320&#x27;, &#x27;embedding_321&#x27;, &#x27;embedding_322&#x27;, &#x27;embedding_323&#x27;, &#x27;embedding_324&#x27;, &#x27;embedding_325&#x27;, &#x27;embedding_326&#x27;, &#x27;embedding_327&#x27;, &#x27;embedding_328&#x27;, &#x27;embedding_329&#x27;, &#x27;embedding_330&#x27;, &#x27;embedding_331&#x27;, &#x27;embedding_332&#x27;, &#x27;embedding_333&#x27;, &#x27;embedding_334&#x27;, &#x27;embedding_335&#x27;, &#x27;embedding_336&#x27;, &#x27;embedding_337&#x27;, &#x27;embedding_338&#x27;, &#x27;embedding_339&#x27;, &#x27;embedding_340&#x27;, &#x27;embedding_341&#x27;, &#x27;embedding_342&#x27;, &#x27;embedding_343&#x27;, &#x27;embedding_344&#x27;, &#x27;embedding_345&#x27;, &#x27;embedding_346&#x27;, &#x27;embedding_347&#x27;, &#x27;embedding_348&#x27;, &#x27;embedding_349&#x27;, &#x27;embedding_350&#x27;, &#x27;embedding_351&#x27;, &#x27;embedding_352&#x27;, &#x27;embedding_353&#x27;, &#x27;embedding_354&#x27;, &#x27;embedding_355&#x27;, &#x27;embedding_356&#x27;, &#x27;embedding_357&#x27;, &#x27;embedding_358&#x27;, &#x27;embedding_359&#x27;, &#x27;embedding_360&#x27;, &#x27;embedding_361&#x27;, &#x27;embedding_362&#x27;, &#x27;embedding_363&#x27;, &#x27;embedding_364&#x27;, &#x27;embedding_365&#x27;, &#x27;embedding_366&#x27;, &#x27;embedding_367&#x27;, &#x27;embedding_368&#x27;, &#x27;embedding_369&#x27;, &#x27;embedding_370&#x27;, &#x27;embedding_371&#x27;, &#x27;embedding_372&#x27;, &#x27;embedding_373&#x27;, &#x27;embedding_374&#x27;, &#x27;embedding_375&#x27;, &#x27;embedding_376&#x27;, &#x27;embedding_377&#x27;, &#x27;embedding_378&#x27;, &#x27;embedding_379&#x27;, &#x27;embedding_380&#x27;, &#x27;embedding_381&#x27;, &#x27;embedding_382&#x27;, &#x27;embedding_383&#x27;, &#x27;embedding_384&#x27;, &#x27;embedding_385&#x27;, &#x27;embedding_386&#x27;, &#x27;embedding_387&#x27;, &#x27;embedding_388&#x27;, &#x27;embedding_389&#x27;, &#x27;embedding_390&#x27;, &#x27;embedding_391&#x27;, &#x27;embedding_392&#x27;, &#x27;embedding_393&#x27;, &#x27;embedding_394&#x27;, &#x27;embedding_395&#x27;, &#x27;embedding_396&#x27;, &#x27;embedding_397&#x27;, &#x27;embedding_398&#x27;, &#x27;embedding_399&#x27;, &#x27;embedding_400&#x27;, &#x27;embedding_401&#x27;, &#x27;embedding_402&#x27;, &#x27;embedding_403&#x27;, &#x27;embedding_404&#x27;, &#x27;embedding_405&#x27;, &#x27;embedding_406&#x27;, &#x27;embedding_407&#x27;, &#x27;embedding_408&#x27;, &#x27;embedding_409&#x27;, &#x27;embedding_410&#x27;, &#x27;embedding_411&#x27;, &#x27;embedding_412&#x27;, &#x27;embedding_413&#x27;, &#x27;embedding_414&#x27;, &#x27;embedding_415&#x27;, &#x27;embedding_416&#x27;, &#x27;embedding_417&#x27;, &#x27;embedding_418&#x27;, &#x27;embedding_419&#x27;, &#x27;embedding_420&#x27;, &#x27;embedding_421&#x27;, &#x27;embedding_422&#x27;, &#x27;embedding_423&#x27;, &#x27;embedding_424&#x27;, &#x27;embedding_425&#x27;, &#x27;embedding_426&#x27;, &#x27;embedding_427&#x27;, &#x27;embedding_428&#x27;, &#x27;embedding_429&#x27;, &#x27;embedding_430&#x27;, &#x27;embedding_431&#x27;, &#x27;embedding_432&#x27;, &#x27;embedding_433&#x27;, &#x27;embedding_434&#x27;, &#x27;embedding_435&#x27;, &#x27;embedding_436&#x27;, &#x27;embedding_437&#x27;, &#x27;embedding_438&#x27;, &#x27;embedding_439&#x27;, &#x27;embedding_440&#x27;, &#x27;embedding_441&#x27;, &#x27;embedding_442&#x27;, &#x27;embedding_443&#x27;, &#x27;embedding_444&#x27;, &#x27;embedding_445&#x27;, &#x27;embedding_446&#x27;, &#x27;embedding_447&#x27;, &#x27;embedding_448&#x27;, &#x27;embedding_449&#x27;, &#x27;embedding_450&#x27;, &#x27;embedding_451&#x27;, &#x27;embedding_452&#x27;, &#x27;embedding_453&#x27;, &#x27;embedding_454&#x27;, &#x27;embedding_455&#x27;, &#x27;embedding_456&#x27;, &#x27;embedding_457&#x27;, &#x27;embedding_458&#x27;, &#x27;embedding_459&#x27;, &#x27;embedding_460&#x27;, &#x27;embedding_461&#x27;, &#x27;embedding_462&#x27;, &#x27;embedding_463&#x27;, &#x27;embedding_464&#x27;, &#x27;embedding_465&#x27;, &#x27;embedding_466&#x27;, &#x27;embedding_467&#x27;, &#x27;embedding_468&#x27;, &#x27;embedding_469&#x27;, &#x27;embedding_470&#x27;, &#x27;embedding_471&#x27;, &#x27;embedding_472&#x27;, &#x27;embedding_473&#x27;, &#x27;embedding_474&#x27;, &#x27;embedding_475&#x27;, &#x27;embedding_476&#x27;, &#x27;embedding_477&#x27;, &#x27;embedding_478&#x27;, &#x27;embedding_479&#x27;, &#x27;embedding_480&#x27;, &#x27;embedding_481&#x27;, &#x27;embedding_482&#x27;, &#x27;embedding_483&#x27;, &#x27;embedding_484&#x27;, &#x27;embedding_485&#x27;, &#x27;embedding_486&#x27;, &#x27;embedding_487&#x27;, &#x27;embedding_488&#x27;, &#x27;embedding_489&#x27;, &#x27;embedding_490&#x27;, &#x27;embedding_491&#x27;, &#x27;embedding_492&#x27;, &#x27;embedding_493&#x27;, &#x27;embedding_494&#x27;, &#x27;embedding_495&#x27;, &#x27;embedding_496&#x27;, &#x27;embedding_497&#x27;, &#x27;embedding_498&#x27;, &#x27;embedding_499&#x27;, &#x27;embedding_500&#x27;, &#x27;embedding_501&#x27;, &#x27;embedding_502&#x27;, &#x27;embedding_503&#x27;, &#x27;embedding_504&#x27;, &#x27;embedding_505&#x27;, &#x27;embedding_506&#x27;, &#x27;embedding_507&#x27;, &#x27;embedding_508&#x27;, &#x27;embedding_509&#x27;, &#x27;embedding_510&#x27;, &#x27;embedding_511&#x27;, &#x27;embedding_512&#x27;, &#x27;embedding_513&#x27;, &#x27;embedding_514&#x27;, &#x27;embedding_515&#x27;, &#x27;embedding_516&#x27;, &#x27;embedding_517&#x27;, &#x27;embedding_518&#x27;, &#x27;embedding_519&#x27;, &#x27;embedding_520&#x27;, &#x27;embedding_521&#x27;, &#x27;embedding_522&#x27;, &#x27;embedding_523&#x27;, &#x27;embedding_524&#x27;, &#x27;embedding_525&#x27;, &#x27;embedding_526&#x27;, &#x27;embedding_527&#x27;, &#x27;embedding_528&#x27;, &#x27;embedding_529&#x27;, &#x27;embedding_530&#x27;, &#x27;embedding_531&#x27;, &#x27;embedding_532&#x27;, &#x27;embedding_533&#x27;, &#x27;embedding_534&#x27;, &#x27;embedding_535&#x27;, &#x27;embedding_536&#x27;, &#x27;embedding_537&#x27;, &#x27;embedding_538&#x27;, &#x27;embedding_539&#x27;, &#x27;embedding_540&#x27;, &#x27;embedding_541&#x27;, &#x27;embedding_542&#x27;, &#x27;embedding_543&#x27;, &#x27;embedding_544&#x27;, &#x27;embedding_545&#x27;, &#x27;embedding_546&#x27;, &#x27;embedding_547&#x27;, &#x27;embedding_548&#x27;, &#x27;embedding_549&#x27;, &#x27;embedding_550&#x27;, &#x27;embedding_551&#x27;, &#x27;embedding_552&#x27;, &#x27;embedding_553&#x27;, &#x27;embedding_554&#x27;, &#x27;embedding_555&#x27;, &#x27;embedding_556&#x27;, &#x27;embedding_557&#x27;, &#x27;embedding_558&#x27;, &#x27;embedding_559&#x27;, &#x27;embedding_560&#x27;, &#x27;embedding_561&#x27;, &#x27;embedding_562&#x27;, &#x27;embedding_563&#x27;, &#x27;embedding_564&#x27;, &#x27;embedding_565&#x27;, &#x27;embedding_566&#x27;, &#x27;embedding_567&#x27;, &#x27;embedding_568&#x27;, &#x27;embedding_569&#x27;, &#x27;embedding_570&#x27;, &#x27;embedding_571&#x27;, &#x27;embedding_572&#x27;, &#x27;embedding_573&#x27;, &#x27;embedding_574&#x27;, &#x27;embedding_575&#x27;, &#x27;embedding_576&#x27;, &#x27;embedding_577&#x27;, &#x27;embedding_578&#x27;, &#x27;embedding_579&#x27;, &#x27;embedding_580&#x27;, &#x27;embedding_581&#x27;, &#x27;embedding_582&#x27;, &#x27;embedding_583&#x27;, &#x27;embedding_584&#x27;, &#x27;embedding_585&#x27;, &#x27;embedding_586&#x27;, &#x27;embedding_587&#x27;, &#x27;embedding_588&#x27;, &#x27;embedding_589&#x27;, &#x27;embedding_590&#x27;, &#x27;embedding_591&#x27;, &#x27;embedding_592&#x27;, &#x27;embedding_593&#x27;, &#x27;embedding_594&#x27;, &#x27;embedding_595&#x27;, &#x27;embedding_596&#x27;, &#x27;embedding_597&#x27;, &#x27;embedding_598&#x27;, &#x27;embedding_599&#x27;, &#x27;embedding_600&#x27;, &#x27;embedding_601&#x27;, &#x27;embedding_602&#x27;, &#x27;embedding_603&#x27;, &#x27;embedding_604&#x27;, &#x27;embedding_605&#x27;, &#x27;embedding_606&#x27;, &#x27;embedding_607&#x27;, &#x27;embedding_608&#x27;, &#x27;embedding_609&#x27;, &#x27;embedding_610&#x27;, &#x27;embedding_611&#x27;, &#x27;embedding_612&#x27;, &#x27;embedding_613&#x27;, &#x27;embedding_614&#x27;, &#x27;embedding_615&#x27;, &#x27;embedding_616&#x27;, &#x27;embedding_617&#x27;, &#x27;embedding_618&#x27;, &#x27;embedding_619&#x27;, &#x27;embedding_620&#x27;, &#x27;embedding_621&#x27;, &#x27;embedding_622&#x27;, &#x27;embedding_623&#x27;, &#x27;embedding_624&#x27;, &#x27;embedding_625&#x27;, &#x27;embedding_626&#x27;, &#x27;embedding_627&#x27;, &#x27;embedding_628&#x27;, &#x27;embedding_629&#x27;, &#x27;embedding_630&#x27;, &#x27;embedding_631&#x27;, &#x27;embedding_632&#x27;, &#x27;embedding_633&#x27;, &#x27;embedding_634&#x27;, &#x27;embedding_635&#x27;, &#x27;embedding_636&#x27;, &#x27;embedding_637&#x27;, &#x27;embedding_638&#x27;, &#x27;embedding_639&#x27;, &#x27;embedding_640&#x27;, &#x27;embedding_641&#x27;, &#x27;embedding_642&#x27;, &#x27;embedding_643&#x27;, &#x27;embedding_644&#x27;, &#x27;embedding_645&#x27;, &#x27;embedding_646&#x27;, &#x27;embedding_647&#x27;, &#x27;embedding_648&#x27;, &#x27;embedding_649&#x27;, &#x27;embedding_650&#x27;, &#x27;embedding_651&#x27;, &#x27;embedding_652&#x27;, &#x27;embedding_653&#x27;, &#x27;embedding_654&#x27;, &#x27;embedding_655&#x27;, &#x27;embedding_656&#x27;, &#x27;embedding_657&#x27;, &#x27;embedding_658&#x27;, &#x27;embedding_659&#x27;, &#x27;embedding_660&#x27;, &#x27;embedding_661&#x27;, &#x27;embedding_662&#x27;, &#x27;embedding_663&#x27;, &#x27;embedding_664&#x27;, &#x27;embedding_665&#x27;, &#x27;embedding_666&#x27;, &#x27;embedding_667&#x27;, &#x27;embedding_668&#x27;, &#x27;embedding_669&#x27;, &#x27;embedding_670&#x27;, &#x27;embedding_671&#x27;, &#x27;embedding_672&#x27;, &#x27;embedding_673&#x27;, &#x27;embedding_674&#x27;, &#x27;embedding_675&#x27;, &#x27;embedding_676&#x27;, &#x27;embedding_677&#x27;, &#x27;embedding_678&#x27;, &#x27;embedding_679&#x27;, &#x27;embedding_680&#x27;, &#x27;embedding_681&#x27;, &#x27;embedding_682&#x27;, &#x27;embedding_683&#x27;, &#x27;embedding_684&#x27;, &#x27;embedding_685&#x27;, &#x27;embedding_686&#x27;, &#x27;embedding_687&#x27;, &#x27;embedding_688&#x27;, &#x27;embedding_689&#x27;, &#x27;embedding_690&#x27;, &#x27;embedding_691&#x27;, &#x27;embedding_692&#x27;, &#x27;embedding_693&#x27;, &#x27;embedding_694&#x27;, &#x27;embedding_695&#x27;, &#x27;embedding_696&#x27;, &#x27;embedding_697&#x27;, &#x27;embedding_698&#x27;, &#x27;embedding_699&#x27;, &#x27;embedding_700&#x27;, &#x27;embedding_701&#x27;, &#x27;embedding_702&#x27;, &#x27;embedding_703&#x27;, &#x27;embedding_704&#x27;, &#x27;embedding_705&#x27;, &#x27;embedding_706&#x27;, &#x27;embedding_707&#x27;, &#x27;embedding_708&#x27;, &#x27;embedding_709&#x27;, &#x27;embedding_710&#x27;, &#x27;embedding_711&#x27;, &#x27;embedding_712&#x27;, &#x27;embedding_713&#x27;, &#x27;embedding_714&#x27;, &#x27;embedding_715&#x27;, &#x27;embedding_716&#x27;, &#x27;embedding_717&#x27;, &#x27;embedding_718&#x27;, &#x27;embedding_719&#x27;, &#x27;embedding_720&#x27;, &#x27;embedding_721&#x27;, &#x27;embedding_722&#x27;, &#x27;embedding_723&#x27;, &#x27;embedding_724&#x27;, &#x27;embedding_725&#x27;, &#x27;embedding_726&#x27;, &#x27;embedding_727&#x27;, &#x27;embedding_728&#x27;, &#x27;embedding_729&#x27;, &#x27;embedding_730&#x27;, &#x27;embedding_731&#x27;, &#x27;embedding_732&#x27;, &#x27;embedding_733&#x27;, &#x27;embedding_734&#x27;, &#x27;embedding_735&#x27;, &#x27;embedding_736&#x27;, &#x27;embedding_737&#x27;, &#x27;embedding_738&#x27;, &#x27;embedding_739&#x27;, &#x27;embedding_740&#x27;, &#x27;embedding_741&#x27;, &#x27;embedding_742&#x27;, &#x27;embedding_743&#x27;, &#x27;embedding_744&#x27;, &#x27;embedding_745&#x27;, &#x27;embedding_746&#x27;, &#x27;embedding_747&#x27;, &#x27;embedding_748&#x27;, &#x27;embedding_749&#x27;, &#x27;embedding_750&#x27;, &#x27;embedding_751&#x27;, &#x27;embedding_752&#x27;, &#x27;embedding_753&#x27;, &#x27;embedding_754&#x27;, &#x27;embedding_755&#x27;, &#x27;embedding_756&#x27;, &#x27;embedding_757&#x27;, &#x27;embedding_758&#x27;, &#x27;embedding_759&#x27;, &#x27;embedding_760&#x27;, &#x27;embedding_761&#x27;, &#x27;embedding_762&#x27;, &#x27;embedding_763&#x27;, &#x27;embedding_764&#x27;, &#x27;embedding_765&#x27;, &#x27;embedding_766&#x27;, &#x27;embedding_767&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('str_preprocessor',\n",
       "                                                  CountVectorizer(max_features=100,\n",
       "                                                                  stop_words=['i',\n",
       "                                                                              'me',\n",
       "                                                                              'my',\n",
       "                                                                              'myself',\n",
       "                                                                              'we',\n",
       "                                                                              'our',\n",
       "                                                                              'ours',\n",
       "                                                                              'ourselves',\n",
       "                                                                              'you',\n",
       "                                                                              \"you're\",\n",
       "                                                                              \"you've\",\n",
       "                                                                              \"you'll\",\n",
       "                                                                              \"you'd\",\n",
       "                                                                              'your',\n",
       "                                                                              'yours',\n",
       "                                                                              'yourself',\n",
       "                                                                              'yourselves',\n",
       "                                                                              'he',\n",
       "                                                                              'him',\n",
       "                                                                              'his',\n",
       "                                                                              'himself',\n",
       "                                                                              'she',\n",
       "                                                                              \"she's\",\n",
       "                                                                              'her',\n",
       "                                                                              'hers',\n",
       "                                                                              'herself',\n",
       "                                                                              'it',\n",
       "                                                                              \"it's\",\n",
       "                                                                              'its',\n",
       "                                                                              'itself', ...]),\n",
       "                                                  'container-title'),\n",
       "                                                 ('neotoma_encoder',\n",
       "                                                  NeotomaOneHotEncoder(min_count=10),\n",
       "                                                  ['subject',\n",
       "                                                   'container-title'])])),\n",
       "                ('simpleimputer',\n",
       "                 SimpleImputer(fill_value=0, strategy='constant')),\n",
       "                ('logisticregression', LogisticRegression(C=1, max_iter=1000))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict['model'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classifier': ['LogisticRegression',\n",
       "   'DecisionTreeClassifier',\n",
       "   'KNeighborsClassifier',\n",
       "   'BernoulliNB',\n",
       "   'RandomForestClassifier'],\n",
       "  'Fit Time': [datetime.timedelta(seconds=31, microseconds=85787),\n",
       "   datetime.timedelta(seconds=43, microseconds=942452),\n",
       "   datetime.timedelta(seconds=24, microseconds=852635),\n",
       "   datetime.timedelta(seconds=11, microseconds=834530),\n",
       "   datetime.timedelta(seconds=82, microseconds=419802)],\n",
       "  'train_recall': [0.8827133324324498,\n",
       "   0.9221791085114187,\n",
       "   0.7453433974891089,\n",
       "   0.7292072868606141,\n",
       "   1.0],\n",
       "  'train_f1': [0.9290245071231624,\n",
       "   0.9166238498216931,\n",
       "   0.7406612668708946,\n",
       "   0.5792429734212079,\n",
       "   0.9998209489704566],\n",
       "  'train_precision': [0.9804951557692407,\n",
       "   0.9119517133867658,\n",
       "   0.7361372034833796,\n",
       "   0.48047606808465426,\n",
       "   0.9996422182468694],\n",
       "  'train_accuracy': [0.9553019881970013,\n",
       "   0.944483090681594,\n",
       "   0.8270329369091346,\n",
       "   0.648955668456263,\n",
       "   0.999881164587047],\n",
       "  'test_recall': [0.7402980472764644,\n",
       "   0.6399897225077081,\n",
       "   0.7001541623843781,\n",
       "   0.710082219938335,\n",
       "   0.6211408016443988],\n",
       "  'test_f1': [0.7788166747957469,\n",
       "   0.6244442581813096,\n",
       "   0.6878111740479184,\n",
       "   0.5688625363373115,\n",
       "   0.7067853140310388],\n",
       "  'test_precision': [0.8219061678694464,\n",
       "   0.6126652073162401,\n",
       "   0.6762395204513933,\n",
       "   0.4748444968129693,\n",
       "   0.8221222445265592],\n",
       "  'test_accuracy': [0.8606752629793011,\n",
       "   0.7456271914941748,\n",
       "   0.789345096708517,\n",
       "   0.6438264902160389,\n",
       "   0.8297556837461826]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
