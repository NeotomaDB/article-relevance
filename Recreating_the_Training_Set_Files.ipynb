{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.logs import get_logger\n",
    "import src.article_relevance as ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Prepare 3 Training PQ Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Neotoma & Pollen files from CrossRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "neotoma_fixed = pd.read_csv('data/raw/neotoma_crossref_fixed.csv')\n",
    "pollenDF = pd.read_csv('data/raw/pollen_doc_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['siteid', 'sitename', 'longitudeeast', 'latitudenorth', 'longitudewest',\n",
       "       'latitudesouth', 'altitude', 'area', 'sitedescription', 'notes',\n",
       "       'recdatecreated', 'recdatemodified', 'geog', 'datasetid',\n",
       "       'collectionunitid', 'datasettypeid', 'datasetname', 'notes-2',\n",
       "       'recdatecreated-2', 'recdatemodified-2', 'embargoid', 'citation', 'doi',\n",
       "       'status_code', 'doi_in_crossref'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neotoma_fixed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting DOIs and extracing data from CrossRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.2307/1551601   not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.2307/1551050   not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI widga, c., s.n. lengyel, j. saunders, g. hodgins, j.d. walker, and a.d. wanamaker. 2017. late pleistocene proboscidean population dynamics in the north american midcontinent. boreas 46(4):772-782. [doi: 10.1111/bor.12235] not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI joyce, d.j. 2006. chronology and new research on the schaefer mammoth (? mammuthus primigenius) site, kenosha county, wisconsin, usa,. quaternary international 142:44-57. [doi: doi:10.1016/j.quaint.2005.03.004] not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI fiedel, s.j. 2018. the spore conundrum: does a dung fungus decline signal humans' arrival in the eastern united states?. quaternary international 466:247e255. [doi: doi.org/10.1016/j.quaint.2015.11.130] not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.1016/j.revpalbo.2004.09.004   not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI overstreet, d.f., and m.f. kolb. 2003. geoarchaeological contexts for late pleistocene archaeological sites with human‐modified woolly mammoth remains in southeastern wisconsin, usa. geoarchaeology 18(1):91-114. [doi: doi:10.1002/gea.10052] not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.1016/j.quascirev.2016.09.023. not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.15036/arerugi.72.18 not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.3760/cma.j.cn112150-20220508-00458 not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.13345/j.cjb.220336 not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.1093/lambio/ovac017 not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.4103/ijd.ijd_405_22 not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI nan not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n",
      "/Users/sedv8808/HT-Data/UWisc/article-relevance/src/article_relevance/crossRefQuery.py:25: Warning: DOI 10.13201/j.issn.2096-7993.2023.05.012 not found in CrossRef\n",
      "  warnings.warn(warning_msg, category=Warning)\n"
     ]
    }
   ],
   "source": [
    "neotomaCrossRef = ar.crossRefQuery(neotoma_fixed['doi'].unique().tolist())\n",
    "pollenCrossRef =  ar.crossRefQuery(pollenDF['doi'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([neotomaCrossRef, pollenCrossRef])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>subject</th>\n",
       "      <th>abstract</th>\n",
       "      <th>container-title</th>\n",
       "      <th>language</th>\n",
       "      <th>published</th>\n",
       "      <th>publisher</th>\n",
       "      <th>URL</th>\n",
       "      <th>CrossRefQueryDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1111/j.1438-8677.1972.tb03139.x</td>\n",
       "      <td>[Remarks on the Late‐glacial and Holocene Hist...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'given': 'Magdalena', 'family': 'Ralska‐Jasi...</td>\n",
       "      <td>[Plant Science, Ecology, Evolution, Behavior a...</td>\n",
       "      <td></td>\n",
       "      <td>[Berichte der Deutschen Botanischen Gesellschaft]</td>\n",
       "      <td>en</td>\n",
       "      <td>{'date-parts': [[1972, 5]]}</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>http://dx.doi.org/10.1111/j.1438-8677.1972.tb0...</td>\n",
       "      <td>2023-08-30 16:49:23.814159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.2307/1441188</td>\n",
       "      <td>[A New Species of Geochelone from the Pleistoc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'given': 'Walter', 'family': 'Auffenberg', '...</td>\n",
       "      <td>[Animal Science and Zoology, Aquatic Science, ...</td>\n",
       "      <td></td>\n",
       "      <td>[Copeia]</td>\n",
       "      <td></td>\n",
       "      <td>{'date-parts': [[1962, 9, 28]]}</td>\n",
       "      <td>JSTOR</td>\n",
       "      <td>http://dx.doi.org/10.2307/1441188</td>\n",
       "      <td>2023-08-30 16:49:24.198599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI  \\\n",
       "0  10.1111/j.1438-8677.1972.tb03139.x   \n",
       "1                     10.2307/1441188   \n",
       "\n",
       "                                               title subtitle  \\\n",
       "0  [Remarks on the Late‐glacial and Holocene Hist...       []   \n",
       "1  [A New Species of Geochelone from the Pleistoc...       []   \n",
       "\n",
       "                                              author  \\\n",
       "0  [{'given': 'Magdalena', 'family': 'Ralska‐Jasi...   \n",
       "1  [{'given': 'Walter', 'family': 'Auffenberg', '...   \n",
       "\n",
       "                                             subject abstract  \\\n",
       "0  [Plant Science, Ecology, Evolution, Behavior a...            \n",
       "1  [Animal Science and Zoology, Aquatic Science, ...            \n",
       "\n",
       "                                     container-title language  \\\n",
       "0  [Berichte der Deutschen Botanischen Gesellschaft]       en   \n",
       "1                                           [Copeia]            \n",
       "\n",
       "                         published publisher  \\\n",
       "0      {'date-parts': [[1972, 5]]}     Wiley   \n",
       "1  {'date-parts': [[1962, 9, 28]]}     JSTOR   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  http://dx.doi.org/10.1111/j.1438-8677.1972.tb0...   \n",
       "1                  http://dx.doi.org/10.2307/1441188   \n",
       "\n",
       "           CrossRefQueryDate  \n",
       "0 2023-08-30 16:49:23.814159  \n",
       "1 2023-08-30 16:49:24.198599  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-30 16:57:28,206 - dataPreprocessing.py:21 - dataPreprocessing - INFO - Prediction data preprocessing begin.\n",
      "2023-08-30 16:57:28,265 - dataPreprocessing.py:46 - dataPreprocessing - INFO - Running article language imputation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-30 16:57:28,280 - dataPreprocessing.py:62 - dataPreprocessing - INFO - 151 articles require language imputation\n",
      "2023-08-30 16:57:28,281 - dataPreprocessing.py:64 - dataPreprocessing - INFO - 5 cannot be imputed due to too short text metadata(title, subtitle and abstract less than 5 character).\n",
      "2023-08-30 16:57:29,938 - dataPreprocessing.py:72 - dataPreprocessing - INFO - Missing language imputation completed\n",
      "2023-08-30 16:57:29,941 - dataPreprocessing.py:73 - dataPreprocessing - INFO - After imputation, there are 14 non-English articles in total excluded from the prediction pipeline.\n"
     ]
    }
   ],
   "source": [
    "preprocessedDF = ar.dataPreprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>subject</th>\n",
       "      <th>abstract</th>\n",
       "      <th>container-title</th>\n",
       "      <th>language</th>\n",
       "      <th>published</th>\n",
       "      <th>publisher</th>\n",
       "      <th>URL</th>\n",
       "      <th>CrossRefQueryDate</th>\n",
       "      <th>validForPrediction</th>\n",
       "      <th>titleSubtitleAbstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1111/j.1438-8677.1972.tb03139.x</td>\n",
       "      <td>Remarks on the Late‐glacial and Holocene Histo...</td>\n",
       "      <td></td>\n",
       "      <td>[[{'given': 'Magdalena', 'family': 'Ralska‐Jas...</td>\n",
       "      <td>Plant Science Ecology, Evolution, Behavior and...</td>\n",
       "      <td></td>\n",
       "      <td>Berichte der Deutschen Botanischen Gesellschaft</td>\n",
       "      <td>en</td>\n",
       "      <td>{'date-parts': [[1972, 5]]}</td>\n",
       "      <td>Wiley</td>\n",
       "      <td>http://dx.doi.org/10.1111/j.1438-8677.1972.tb0...</td>\n",
       "      <td>2023-08-30 16:49:23.814159</td>\n",
       "      <td>1</td>\n",
       "      <td>remarks on the late‐glacial and holocene histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.2307/1441188</td>\n",
       "      <td>A New Species of Geochelone from the Pleistoce...</td>\n",
       "      <td></td>\n",
       "      <td>[[{'given': 'Walter', 'family': 'Auffenberg', ...</td>\n",
       "      <td>Animal Science and Zoology Aquatic Science Eco...</td>\n",
       "      <td></td>\n",
       "      <td>Copeia</td>\n",
       "      <td>en</td>\n",
       "      <td>{'date-parts': [[1962, 9, 28]]}</td>\n",
       "      <td>JSTOR</td>\n",
       "      <td>http://dx.doi.org/10.2307/1441188</td>\n",
       "      <td>2023-08-30 16:49:24.198599</td>\n",
       "      <td>1</td>\n",
       "      <td>a new species of geochelone from the pleistoce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  DOI  \\\n",
       "0  10.1111/j.1438-8677.1972.tb03139.x   \n",
       "1                     10.2307/1441188   \n",
       "\n",
       "                                               title subtitle  \\\n",
       "0  Remarks on the Late‐glacial and Holocene Histo...            \n",
       "1  A New Species of Geochelone from the Pleistoce...            \n",
       "\n",
       "                                              author  \\\n",
       "0  [[{'given': 'Magdalena', 'family': 'Ralska‐Jas...   \n",
       "1  [[{'given': 'Walter', 'family': 'Auffenberg', ...   \n",
       "\n",
       "                                             subject abstract  \\\n",
       "0  Plant Science Ecology, Evolution, Behavior and...            \n",
       "1  Animal Science and Zoology Aquatic Science Eco...            \n",
       "\n",
       "                                   container-title language  \\\n",
       "0  Berichte der Deutschen Botanischen Gesellschaft       en   \n",
       "1                                           Copeia       en   \n",
       "\n",
       "                         published publisher  \\\n",
       "0      {'date-parts': [[1972, 5]]}     Wiley   \n",
       "1  {'date-parts': [[1962, 9, 28]]}     JSTOR   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  http://dx.doi.org/10.1111/j.1438-8677.1972.tb0...   \n",
       "1                  http://dx.doi.org/10.2307/1441188   \n",
       "\n",
       "           CrossRefQueryDate  validForPrediction  \\\n",
       "0 2023-08-30 16:49:23.814159                   1   \n",
       "1 2023-08-30 16:49:24.198599                   1   \n",
       "\n",
       "                               titleSubtitleAbstract  \n",
       "0  remarks on the late‐glacial and holocene histo...  \n",
       "1  a new species of geochelone from the pleistoce...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessedDF.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this as 1 parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "('cannot mix list and non-list, non-null values', 'Conversion failed for column author with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preprocessedDF\u001b[39m.\u001b[39;49mto_parquet(\u001b[39m'\u001b[39;49m\u001b[39mdata/parquet/neotomaMetadata.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pandas/core/frame.py:2889\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2887\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2889\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[1;32m   2890\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2891\u001b[0m     path,\n\u001b[1;32m   2892\u001b[0m     engine,\n\u001b[1;32m   2893\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2894\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2895\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m   2896\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2897\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2898\u001b[0m )\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pandas/io/parquet.py:411\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    409\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m--> 411\u001b[0m impl\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    412\u001b[0m     df,\n\u001b[1;32m    413\u001b[0m     path_or_buf,\n\u001b[1;32m    414\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    415\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    416\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m    417\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    418\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    419\u001b[0m )\n\u001b[1;32m    421\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    422\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, io\u001b[39m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pandas/io/parquet.py:159\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     from_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpreserve_index\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m index\n\u001b[0;32m--> 159\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pandas(df, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfrom_pandas_kwargs)\n\u001b[1;32m    161\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    162\u001b[0m     path,\n\u001b[1;32m    163\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     is_dir\u001b[39m=\u001b[39mpartition_cols \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    169\u001b[0m     \u001b[39misinstance\u001b[39m(path_or_handle, io\u001b[39m.\u001b[39mBufferedWriter)\n\u001b[1;32m    170\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(path_or_handle, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_handle\u001b[39m.\u001b[39mname, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m))\n\u001b[1;32m    172\u001b[0m ):\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/table.pxi:3681\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[1;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;49;00m c, f \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[1;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m field_nullable \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mnull_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mField \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m was non-nullable but pandas column \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mhad \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m null values\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[39m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[39m=\u001b[39m field\u001b[39m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(col, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49mtype_, from_pandas\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, safe\u001b[39m=\u001b[39;49msafe)\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/array.pxi:323\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/HT-Data/UWisc/article-relevance/venv/lib/python3.11/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: ('cannot mix list and non-list, non-null values', 'Conversion failed for column author with type object')"
     ]
    }
   ],
   "source": [
    "preprocessedDF.to_parquet('data/parquet/neotomaMetadata.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Data File\n",
    "\n",
    "We need a 2nd file that contains the following info:\n",
    "```python\n",
    "['DOI', 'Annotation', 'Annotator', 'Annotation_Date']\n",
    "```\n",
    "\n",
    "In the `pollen.csv` file Dr. Goring has done already some manual annotation of whether a particular article would belong to Neotoma or not. All files in the `neotoma.csv` file belong to Neotoma. \n",
    "\n",
    "In a different setting, this annotations would be made using the **Data Review Tool** and stored to complement the parquet file, for now, I am going to do a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "annotation_cols = ['DOI', 'annotation', 'Annotator', 'Annotation_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neotoma_fixed['annotation'] = 'Neotoma'\n",
    "neotoma_fixed['annotator'] = 'Simon J. Goring'\n",
    "neotoma_fixed['annotationDate'] = datetime.now()\n",
    "neotomaAnnotation = neotoma_fixed[annotation_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollenDF['annotation'] = pollenDF['Label']\n",
    "pollenDF['annotator'] = pollenDF['Profile']\n",
    "pollenDF['annotationDate'] = pollenDF['Timestamp']\n",
    "pollenAnnotation = pollenDF[annotation_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullAnnotation = pd.concat([neotomaAnnotation, pollenAnnotation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullAnnotation.to_parquet('data/parquet/neotomaAnnotation.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Parquet\n",
    "\n",
    "The Prediction PQ file will contain the following columns:\n",
    "```python\n",
    "['DOI', 'prediction', 'predict_proba', 'model_metadata', 'prediction_date']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed the data using the provided functions (this has been previously trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddedData = ar.addEmbeddings(preprocessedDF, 'titleSubtitleAbstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the predictions using the AWS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF = ar.relevancePredict(embeddedData, AWS = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the columns we are interested on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionCols = ['DOI', 'prediction', 'predict_proba', 'model_metadata', 'prediction_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF = predictionsDF[predictionCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF.to_parquet('data/parquet/neotomaPredictions.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
